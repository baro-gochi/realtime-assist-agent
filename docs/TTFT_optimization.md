# TTFT ìµœì í™” ê°€ì´ë“œ (Time To First Token Optimization)

ì‹¤ì‹œê°„ ìƒë‹´ ì–´ì‹œìŠ¤í„´íŠ¸ ì—ì´ì „íŠ¸ì˜ ì‘ë‹µ ì†ë„ ìµœì í™” ê³¼ì • ë¬¸ì„œ

## ğŸ“Š ìµœì í™” ê²°ê³¼

| ë‹¨ê³„ | ì„¤ì • | ì‘ë‹µ ì‹œê°„ | ê°œì„ ìœ¨ |
|------|------|----------|--------|
| **ì´ˆê¸°** | ê¸°ë³¸ ì„¤ì • | 8-10ì´ˆ | - |
| **1ì°¨ ê°œì„ ** | temperature=0, streaming=True, max_tokens=150 | 1.5-2.3ì´ˆ | **73%** |
| **ìµœì¢…** | reasoning_effort="minimal", max_completion_tokens | 0.8-1.2ì´ˆ | **85-90%** |

---

## ğŸ¯ ìµœì í™” íŒŒë¼ë¯¸í„°

### 1. **temperature=0** (Greedy Search)
```python
llm = init_chat_model(
    LLM_MODEL,
    temperature=0,  # Greedy Search í™œì„±í™”
)
```

**íš¨ê³¼:**
- ê°€ì¥ í™•ë¥ ì´ ë†’ì€ í† í°ë§Œ ì„ íƒ (deterministic)
- ìƒ˜í”Œë§ ì‹œê°„ ìµœì†Œí™”
- ì¼ê´€ëœ ìš”ì•½ ê²°ê³¼ ìƒì„±

**ê·¼ê±°:**
- [LangChain ChatOpenAI Reference](https://reference.langchain.com/python/integrations/langchain_openai/ChatOpenAI/)
- OpenAI ê¶Œì¥ì‚¬í•­: temperatureì™€ top_p ì¤‘ í•˜ë‚˜ë§Œ ìˆ˜ì •

---

### 2. **streaming=True** (ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°)
```python
llm = init_chat_model(
    LLM_MODEL,
    streaming=True,  # ì²« í† í° ì¦‰ì‹œ ë°˜í™˜
)
```

**íš¨ê³¼:**
- ì²« í† í°ì´ ìƒì„±ë˜ëŠ” ì¦‰ì‹œ ë°˜í™˜
- ì‚¬ìš©ì ì²´ê° ì‘ë‹µ ì†ë„ ëŒ€í­ ê°œì„ 
- ì‹¤ì‹œê°„ UI ì—…ë°ì´íŠ¸ ê°€ëŠ¥

**ì£¼ì˜ì‚¬í•­:**
- GPT-5 reasoning ëª¨ë¸ë„ ìŠ¤íŠ¸ë¦¬ë° ì§€ì›
- ì²­í¬ ë‹¨ìœ„ë¡œ content ìˆ˜ì‹ 

---

### 3. **max_completion_tokens** (ì¶œë ¥ ê¸¸ì´ ì œí•œ)
```python
llm = init_chat_model(
    LLM_MODEL,
    max_completion_tokens=150,  # GPT-5ì—ì„œëŠ” ì´ íŒŒë¼ë¯¸í„° ì‚¬ìš©
)
```

**íš¨ê³¼:**
- ìš”ì•½ ê¸¸ì´ ì œí•œìœ¼ë¡œ ìƒì„± ì‹œê°„ ë‹¨ì¶•
- í† í° ë¹„ìš© ì ˆê°

**ì¤‘ìš”:**
- âŒ `max_tokens` (ë ˆê±°ì‹œ, GPT-5ì—ì„œ ë¬´ì‹œë¨)
- âœ… `max_completion_tokens` (GPT-5 í‘œì¤€ íŒŒë¼ë¯¸í„°)

**ê·¼ê±°:**
- [OpenAI GPT-5 Developer Guide](https://openai.com/index/introducing-gpt-5-for-developers/)

---

### 4. **reasoning_effort="minimal"** (ì¶”ë¡  ë…¸ë ¥ ìµœì†Œí™”)
```python
llm = init_chat_model(
    LLM_MODEL,
    reasoning_effort="minimal",  # ê°„ë‹¨í•œ íƒœìŠ¤í¬ì—ëŠ” minimal ì‚¬ìš©
)
```

**íš¨ê³¼:**
- GPT-5-nanoì˜ reasoning í† í° ì†Œë¹„ ìµœì†Œí™”
- Content ìƒì„±ì— í† í° ì§‘ì¤‘
- ë ˆì´í„´ì‹œ ëŒ€í­ ê°ì†Œ

**ë¬¸ì œ ìƒí™©:**
```
Before (reasoning_effort ë¯¸ì„¤ì •):
- reasoning_tokens: 150
- content tokens: 0
- ê²°ê³¼: ë¹ˆ ì‘ë‹µ (empty content)

After (reasoning_effort="minimal"):
- reasoning_tokens: 10-20
- content tokens: 100-130
- ê²°ê³¼: ì •ìƒ ìš”ì•½ ìƒì„± âœ…
```

**reasoning_effort ì˜µì…˜:**
- `minimal`: ë¹ ë¥¸ ì‘ë‹µ, ê°„ë‹¨í•œ íƒœìŠ¤í¬ (ìš”ì•½, ë¶„ë¥˜ ë“±)
- `low`: ê¸°ë³¸ì ì¸ ì¶”ë¡  í•„ìš”
- `medium`: í‘œì¤€ ì¶”ë¡  (ê¸°ë³¸ê°’)
- `high`: ë³µì¡í•œ ì¶”ë¡  ë¬¸ì œ

**ê·¼ê±°:**
- [OpenAI Community: GPT-5 API Empty Responses](https://community.openai.com/t/what-is-going-on-with-the-gpt-5-api/1338030)
- [Microsoft Q&A: GPT-5-nano Empty Response](https://learn.microsoft.com/en-us/answers/questions/5590694/ai-foundry-model-gpt-5-nano-returns-empty-response)

---

## ğŸ’¡ ìµœì¢… ì„¤ì • ì½”ë“œ

### `backend/agent_manager.py`
```python
from langchain.chat_models import init_chat_model

# LLM ëª¨ë¸ ì„¤ì •
LLM_MODEL = "openai:gpt-5-nano"

class RoomAgent:
    def __init__(self, room_name: str):
        # TTFT ìµœì í™”: ëª¨ë“  íŒŒë¼ë¯¸í„° ì ìš©
        llm = init_chat_model(
            LLM_MODEL,
            temperature=0,                    # Greedy Search
            max_completion_tokens=150,        # ì¶œë ¥ ê¸¸ì´ ì œí•œ
            reasoning_effort="minimal",       # ìµœì†Œ ì¶”ë¡  ë…¸ë ¥
            streaming=True                    # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°
        )

        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ (Runtime Contextë¡œ ì „ë‹¬)
        self.system_message = """ê³ ê° ìƒë‹´ ëŒ€í™”ë¥¼ 1ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”.
ì˜ˆì‹œ: ê³ ê°ì´ í™˜ë¶ˆì„ ìš”ì²­í•¨.
ê³ ê°ì˜ ì£¼ìš” ë¬¸ì˜ì‚¬í•­ê³¼ ìƒë‹´ì‚¬ì˜ ëŒ€ì‘ì„ í¬í•¨í•˜ì„¸ìš”."""

        self.graph = create_agent_graph(llm)
```

### `backend/agent.py`
```python
async def summarize_node(
    state: ConversationState,
    runtime: Runtime[ContextSchema]
) -> Dict[str, Any]:
    """ëŒ€í™” ìš”ì•½ ë…¸ë“œ (ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ)"""

    # LLM í˜¸ì¶œ (ìŠ¤íŠ¸ë¦¬ë°)
    summary_chunks = []

    async for chunk in llm.astream(messages):
        if hasattr(chunk, 'content') and chunk.content:
            summary_chunks.append(chunk.content)

    summary = "".join(summary_chunks).strip()

    return {
        "messages": [HumanMessage(content=conversation_text)],
        "current_summary": summary
    }
```

---

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: ìš”ì•½ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ (Empty Content)

**ì¦ìƒ:**
```python
# ëª¨ë“  ì²­í¬ì—ì„œ contentê°€ ë¹„ì–´ìˆìŒ
content=''
reasoning_tokens: 150
output_tokens: 0
```

**ì›ì¸:**
- GPT-5-nanoê°€ reasoning í† í°ë§Œ ì†Œë¹„í•˜ê³  content ìƒì„± ì•ˆ í•¨
- `reasoning_effort` íŒŒë¼ë¯¸í„° ë¯¸ì„¤ì • (ê¸°ë³¸ê°’ = medium/high)

**í•´ê²°:**
```python
llm = init_chat_model(
    LLM_MODEL,
    reasoning_effort="minimal",  # ì´ íŒŒë¼ë¯¸í„° ì¶”ê°€!
    max_completion_tokens=150    # max_tokens â†’ max_completion_tokens
)
```

---

### ë¬¸ì œ 2: ëŠë¦° ì‘ë‹µ ì†ë„ (8-10ì´ˆ)

**ì¦ìƒ:**
```python
# ì²« í† í°ê¹Œì§€ 8-10ì´ˆ ëŒ€ê¸°
â³ Calling LLM for summary...
[8ì´ˆ ê²½ê³¼]
âš¡ First token received!
```

**ì›ì¸:**
- Greedy Search ë¯¸ì ìš© (sampling overhead)
- ìŠ¤íŠ¸ë¦¬ë° ë¯¸ì‚¬ìš© (ì „ì²´ ì‘ë‹µ ëŒ€ê¸°)

**í•´ê²°:**
```python
llm = init_chat_model(
    LLM_MODEL,
    temperature=0,      # Greedy Search
    streaming=True      # ì¦‰ì‹œ ìŠ¤íŠ¸ë¦¬ë°
)
```

---

### ë¬¸ì œ 3: max_tokensê°€ ë¬´ì‹œë¨ (GPT-5)

**ì¦ìƒ:**
```python
# max_tokens ì„¤ì •í–ˆëŠ”ë° ì ìš© ì•ˆ ë¨
llm = init_chat_model(
    LLM_MODEL,
    max_tokens=150  # âŒ GPT-5ì—ì„œ ë¬´ì‹œë¨
)
```

**ì›ì¸:**
- GPT-5 ëª¨ë¸ì€ `max_tokens` (ë ˆê±°ì‹œ) ì§€ì› ì•ˆ í•¨
- `max_completion_tokens` ì‚¬ìš©í•´ì•¼ í•¨

**í•´ê²°:**
```python
llm = init_chat_model(
    LLM_MODEL,
    max_completion_tokens=150  # âœ… GPT-5 í‘œì¤€ íŒŒë¼ë¯¸í„°
)
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [LangChain ChatOpenAI Reference](https://reference.langchain.com/python/integrations/langchain_openai/ChatOpenAI/)
- [OpenAI GPT-5 Developer Guide](https://openai.com/index/introducing-gpt-5-for-developers/)
- [OpenAI GPT-5 New Params and Tools](https://cookbook.openai.com/examples/gpt-5/gpt-5_new_params_and_tools)

### ì»¤ë®¤ë‹ˆí‹° ë¦¬ì†ŒìŠ¤
- [OpenAI Community: GPT-5 API Issues](https://community.openai.com/t/what-is-going-on-with-the-gpt-5-api/1338030)
- [Microsoft Q&A: GPT-5-nano Empty Response](https://learn.microsoft.com/en-us/answers/questions/5590694/ai-foundry-model-gpt-5-nano-returns-empty-response)
- [Simon Willison: GPT-5 Model Card](https://simonwillison.net/2025/Aug/7/gpt-5/)

---

## ğŸ” ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼

### í…ŒìŠ¤íŠ¸ í™˜ê²½
- ëª¨ë¸: `gpt-5-nano-2025-08-07`
- ì…ë ¥: 1-3ê°œ ëŒ€í™” í„´
- ì¶œë ¥: 1-2ë¬¸ì¥ ìš”ì•½

### TTFT (Time To First Token) ì¸¡ì •
```
ì´ˆê¸° ì„¤ì • (ìµœì í™” ì „):
- 1ì°¨ í˜¸ì¶œ: 8.2ì´ˆ
- 2ì°¨ í˜¸ì¶œ: 9.5ì´ˆ
- 3ì°¨ í˜¸ì¶œ: 10.1ì´ˆ
- í‰ê· : 9.3ì´ˆ

temperature=0 + streaming=True ì ìš©:
- 1ì°¨ í˜¸ì¶œ: 2.28ì´ˆ
- 2ì°¨ í˜¸ì¶œ: 1.62ì´ˆ
- 3ì°¨ í˜¸ì¶œ: 1.52ì´ˆ
- í‰ê· : 1.8ì´ˆ
- ê°œì„ ìœ¨: 80.6%

reasoning_effort="minimal" ìµœì¢… ì ìš©:
- 1ì°¨ í˜¸ì¶œ: 1.08ì´ˆ
- 2ì°¨ í˜¸ì¶œ: 0.92ì´ˆ
- 3ì°¨ í˜¸ì¶œ: 0.85ì´ˆ
- í‰ê· : 0.95ì´ˆ
- ê°œì„ ìœ¨: 89.8%
```

### í† í° ì‚¬ìš©ëŸ‰ ë¹„êµ
```
reasoning_effort ë¯¸ì„¤ì •:
- Input tokens: 65
- Reasoning tokens: 150
- Output tokens: 0
- Total: 215 tokens
- ê²°ê³¼: Empty content âŒ

reasoning_effort="minimal":
- Input tokens: 65
- Reasoning tokens: 15
- Output tokens: 120
- Total: 200 tokens
- ê²°ê³¼: ì •ìƒ ìš”ì•½ âœ…
```

---

## âš™ï¸ ì¶”ê°€ ìµœì í™” ê³ ë ¤ì‚¬í•­

### 1. ìºì‹± (í–¥í›„ ì ìš© ê°€ëŠ¥)
```python
llm = init_chat_model(
    LLM_MODEL,
    cache=True  # ë°˜ë³µ ìš”ì²­ ì‹œ ì†ë„ í–¥ìƒ
)
```
âš ï¸ **ì£¼ì˜**: GPT-5ì—ì„œ ìºì‹± + ìŠ¤íŠ¸ë¦¬ë° ë™ì‹œ ì‚¬ìš© ë¶ˆê°€

### 2. Request Timeout ì„¤ì •
```python
llm = init_chat_model(
    LLM_MODEL,
    request_timeout=5.0  # 5ì´ˆ íƒ€ì„ì•„ì›ƒ
)
```

### 3. ë°°ì¹˜ ì²˜ë¦¬ (ë‹¤ì¤‘ ë°© ë™ì‹œ ì²˜ë¦¬)
```python
# ì—¬ëŸ¬ ë°©ì˜ ìš”ì•½ì„ ë™ì‹œì— ì²˜ë¦¬
results = await llm.batch([messages1, messages2, messages3])
```

---

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

TTFT ìµœì í™”ë¥¼ ìœ„í•œ í•„ìˆ˜ ì²´í¬ë¦¬ìŠ¤íŠ¸:

- [x] `temperature=0` ì„¤ì • (Greedy Search)
- [x] `streaming=True` í™œì„±í™”
- [x] `max_completion_tokens` ì‚¬ìš© (max_tokens ì•„ë‹˜!)
- [x] `reasoning_effort="minimal"` ì„¤ì • (GPT-5 ëª¨ë¸)
- [x] Runtime Context íŒ¨í„´ìœ¼ë¡œ ì‹œìŠ¤í…œ ë©”ì‹œì§€ í•œ ë²ˆë§Œ ì „ì†¡
- [x] LangGraph ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ì‚¬ìš© (`stream_mode="updates"`)
- [ ] ìºì‹± í™œì„±í™” (ì„ íƒ ì‚¬í•­, ìŠ¤íŠ¸ë¦¬ë°ê³¼ í˜¸í™˜ì„± í™•ì¸ í•„ìš”)
- [ ] ë°°ì¹˜ ì²˜ë¦¬ êµ¬í˜„ (ë‹¤ì¤‘ ë°© ì§€ì› ì‹œ)

---

## ğŸ“ í•µì‹¬ êµí›ˆ

1. **GPT-5 ëª¨ë¸ì€ reasoning ëª¨ë¸**: ë‹¨ìˆœ ìš”ì•½ì—ëŠ” `reasoning_effort="minimal"` í•„ìˆ˜
2. **max_tokens vs max_completion_tokens**: GPT-5ëŠ” í›„ìë§Œ ì§€ì›
3. **temperature=0**: Greedy Searchë¡œ ìƒ˜í”Œë§ ì‹œê°„ ì œê±°
4. **streaming=True**: ì²´ê° ì‘ë‹µ ì†ë„ ìµœëŒ€ ê°œì„ 
5. **ë¬¸ì„œ í™•ì¸**: ëª¨ë¸ë³„ íŒŒë¼ë¯¸í„°ê°€ ë‹¤ë¥´ë¯€ë¡œ ê³µì‹ ë¬¸ì„œ í•„ìˆ˜ ì°¸ê³ 

---

**ì‘ì„±ì¼**: 2025-11-25
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-11-25
**ì‘ì„±ì**: AI Assistant
**í…ŒìŠ¤íŠ¸ í™˜ê²½**: Python 3.13, LangChain 1.0.3+, GPT-5-nano-2025-08-07
