{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c5aa5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.types import Send\n",
    "\n",
    "class ConversationState(TypedDict):\n",
    "    \"\"\"ì‹¤ì‹œê°„ ìƒë‹´ ì—ì´ì „íŠ¸ì˜ ìƒíƒœ\"\"\"\n",
    "    \n",
    "    # === WebRTC ìŠ¤íŠ¸ë¦¼ ===\n",
    "    session_id: str                     # WebSocket ì„¸ì…˜ ID\n",
    "    is_streaming: bool                  # ìŠ¤íŠ¸ë¦¬ë° í™œì„± ìƒíƒœ\n",
    "    audio_chunks: list[bytes]           # ëˆ„ì  ì˜¤ë””ì˜¤ ì²­í¬\n",
    "    chunk_timestamps: list[float]       # ê° ì²­í¬ì˜ íƒ€ì„ìŠ¤íƒ¬í”„\n",
    "    \n",
    "    # === ì „ì‚¬ ===\n",
    "    transcription: str                  # í˜„ì¬ ì „ì‚¬ í…ìŠ¤íŠ¸\n",
    "    full_transcript: list[str]          # ëˆ„ì  ì „ì‚¬ íˆìŠ¤í† ë¦¬\n",
    "    \n",
    "    # === ìš”ì•½ (ë³‘ë ¬ ì²˜ë¦¬) ===\n",
    "    current_summary: str                # í˜„ì¬ê¹Œì§€ì˜ ëŒ€í™” ìš”ì•½\n",
    "    \n",
    "    # === RAG (ë³‘ë ¬ ì²˜ë¦¬) ===\n",
    "    query: str                          # RAG ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "    retrieved_docs: list[str]           # ê²€ìƒ‰ëœ ë¬¸ì„œ\n",
    "    suggestion: str                     # ìƒì„±ëœ ë‹µë³€ ì¶”ì²œ\n",
    "    \n",
    "    # === ë©”íƒ€ë°ì´í„° ===\n",
    "    timestamp: float\n",
    "    speaker: str                        # 'agent' | 'customer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "j1y76c62wuq",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_node(state: ConversationState) -> ConversationState:\n",
    "    \"\"\"\n",
    "    ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜ (STT)\n",
    "    ì‹¤ì œ êµ¬í˜„: STT API í˜¸ì¶œ (Google Cloud STT, Deepgram ë“±)\n",
    "    \"\"\"\n",
    "    print(\"ğŸ¤ [transcribe_node] ì‹¤í–‰ ì¤‘...\")\n",
    "    \n",
    "    # TODO: ì‹¤ì œ STT API í˜¸ì¶œ\n",
    "    # transcription = stt_api.transcribe(state['audio_chunks'][-1])\n",
    "    \n",
    "    # Placeholder êµ¬í˜„\n",
    "    transcription = f\"[ì „ì‚¬ í…ìŠ¤íŠ¸ #{len(state.get('full_transcript', []))}]\"\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"transcription\": transcription,\n",
    "        \"full_transcript\": state.get(\"full_transcript\", []) + [transcription],\n",
    "        \"timestamp\": state.get(\"timestamp\", 0.0) + 0.5\n",
    "    }\n",
    "\n",
    "\n",
    "def summarize_node(state: ConversationState) -> ConversationState:\n",
    "    \"\"\"\n",
    "    ëŒ€í™” ìš”ì•½ ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬)\n",
    "    ì‹¤ì œ êµ¬í˜„: LLM ìš”ì•½ ëª¨ë¸ í˜¸ì¶œ\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“ [summarize_node] ì‹¤í–‰ ì¤‘... (ë³‘ë ¬)\")\n",
    "    \n",
    "    # TODO: ì‹¤ì œ ìš”ì•½ LLM í˜¸ì¶œ\n",
    "    # summary = llm.summarize(state['full_transcript'])\n",
    "    \n",
    "    # Placeholder êµ¬í˜„\n",
    "    transcript_count = len(state.get(\"full_transcript\", []))\n",
    "    summary = f\"[ëŒ€í™” ìš”ì•½: {transcript_count}ê°œ ë°œí™” ë¶„ì„ ì™„ë£Œ]\"\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"current_summary\": summary\n",
    "    }\n",
    "\n",
    "\n",
    "def rag_retrieve_node(state: ConversationState) -> ConversationState:\n",
    "    \"\"\"\n",
    "    RAG ê¸°ë°˜ ì§€ì‹ ê²€ìƒ‰ (ë³‘ë ¬ ì²˜ë¦¬)\n",
    "    ì‹¤ì œ êµ¬í˜„: Vector DB ê²€ìƒ‰ (Pinecone, Chroma ë“±)\n",
    "    \"\"\"\n",
    "    print(\"ğŸ” [rag_retrieve_node] ì‹¤í–‰ ì¤‘... (ë³‘ë ¬)\")\n",
    "    \n",
    "    # TODO: ì‹¤ì œ Vector DB ê²€ìƒ‰\n",
    "    # docs = vector_db.search(state['transcription'], top_k=3)\n",
    "    \n",
    "    # Placeholder êµ¬í˜„\n",
    "    query = state.get(\"transcription\", \"\")\n",
    "    docs = [\n",
    "        f\"[ë¬¸ì„œ 1: {query}ì— ëŒ€í•œ ê´€ë ¨ ë‚´ìš©]\",\n",
    "        f\"[ë¬¸ì„œ 2: {query}ì— ëŒ€í•œ ì°¸ê³  ìë£Œ]\",\n",
    "        f\"[ë¬¸ì„œ 3: {query}ì— ëŒ€í•œ FAQ]\"\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"query\": query,\n",
    "        \"retrieved_docs\": docs\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_suggestion_node(state: ConversationState) -> ConversationState:\n",
    "    \"\"\"\n",
    "    RAG ê¸°ë°˜ ë‹µë³€ ì¶”ì²œ ìƒì„±\n",
    "    ì‹¤ì œ êµ¬í˜„: LLM ìƒì„± ëª¨ë¸ í˜¸ì¶œ\n",
    "    \"\"\"\n",
    "    print(\"ğŸ’¡ [generate_suggestion_node] ì‹¤í–‰ ì¤‘...\")\n",
    "    \n",
    "    # TODO: ì‹¤ì œ LLM ìƒì„±\n",
    "    # suggestion = llm.generate(\n",
    "    #     context=state['retrieved_docs'],\n",
    "    #     query=state['transcription']\n",
    "    # )\n",
    "    \n",
    "    # Placeholder êµ¬í˜„\n",
    "    docs_summary = f\"{len(state.get('retrieved_docs', []))}ê°œ ë¬¸ì„œ\"\n",
    "    suggestion = f\"[ì¶”ì²œ ë‹µë³€: {docs_summary} ê¸°ë°˜ ìƒì„±]\"\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"suggestion\": suggestion\n",
    "    }\n",
    "\n",
    "\n",
    "def aggregate_node(state: ConversationState) -> ConversationState:\n",
    "    \"\"\"\n",
    "    ë³‘ë ¬ ì²˜ë¦¬ ê²°ê³¼ í†µí•© (Barrier)\n",
    "    \"\"\"\n",
    "    print(\"ğŸ”„ [aggregate_node] ë³‘ë ¬ ê²°ê³¼ í†µí•© ì¤‘...\")\n",
    "    \n",
    "    # ë³‘ë ¬ ì²˜ë¦¬ ê²°ê³¼ í™•ì¸\n",
    "    summary = state.get(\"current_summary\", \"ì—†ìŒ\")\n",
    "    suggestion = state.get(\"suggestion\", \"ì—†ìŒ\")\n",
    "    \n",
    "    print(f\"  â”œâ”€ ìš”ì•½: {summary}\")\n",
    "    print(f\"  â””â”€ ì¶”ì²œ: {suggestion}\")\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c0d4wpopv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê·¸ë˜í”„ êµ¬ì¡° ì •ì˜ ì™„ë£Œ\n",
      "\n",
      "ğŸ“Š ê·¸ë˜í”„ êµ¬ì¡°:\n",
      "\n",
      "START\n",
      "  â†“\n",
      "transcribe_node (ìŒì„± â†’ í…ìŠ¤íŠ¸)\n",
      "  â†“\n",
      "  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "  â†“                      â†“\n",
      "summarize_node      rag_retrieve_node (ë³‘ë ¬)\n",
      "  â†“                      â†“\n",
      "  â†“              generate_suggestion_node\n",
      "  â†“                      â†“\n",
      "  â””â”€â”€â”€â”€â”€â”€â†’ aggregate_node â†â”€â”€\n",
      "               â†“\n",
      "              END\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_graph():\n",
    "    \"\"\"ì‹¤ì‹œê°„ ìƒë‹´ ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ìƒì„±\"\"\"\n",
    "    \n",
    "    graph = StateGraph(ConversationState)\n",
    "  \n",
    "    graph.add_node(\"transcribe\", transcribe_node)\n",
    "    graph.add_node(\"summarize\", summarize_node)\n",
    "    graph.add_node(\"rag_retrieve\", rag_retrieve_node)\n",
    "    graph.add_node(\"generate_suggestion\", generate_suggestion_node)\n",
    "    graph.add_node(\"aggregate\", aggregate_node)\n",
    "    \n",
    "    # START â†’ transcribe\n",
    "    graph.add_edge(START, \"transcribe\")\n",
    "    \n",
    "    # transcribe â†’ ë³‘ë ¬ ë¶„ê¸° [summarize, rag_retrieve]\n",
    "    graph.add_edge(\"transcribe\", \"summarize\")\n",
    "    graph.add_edge(\"transcribe\", \"rag_retrieve\")\n",
    "    \n",
    "    # ë³‘ë ¬ ê²½ë¡œ â†’ aggregate (Barrier)\n",
    "    graph.add_edge(\"summarize\", \"aggregate\")\n",
    "    \n",
    "    # rag_retrieve â†’ generate_suggestion â†’ aggregate\n",
    "    graph.add_edge(\"rag_retrieve\", \"generate_suggestion\")\n",
    "    graph.add_edge(\"generate_suggestion\", \"aggregate\")\n",
    "    \n",
    "    # aggregate â†’ END\n",
    "    graph.add_edge(\"aggregate\", END)\n",
    "    \n",
    "    return graph\n",
    "\n",
    "# ê·¸ë˜í”„ ìƒì„±\n",
    "workflow = create_graph()\n",
    "graph = workflow.compile()\n",
    "\n",
    "print(\"âœ… ê·¸ë˜í”„ êµ¬ì¡° ì •ì˜ ì™„ë£Œ\")\n",
    "print(\"\\nğŸ“Š ê·¸ë˜í”„ êµ¬ì¡°:\")\n",
    "print(\"\"\"\n",
    "START\n",
    "  â†“\n",
    "transcribe_node (ìŒì„± â†’ í…ìŠ¤íŠ¸)\n",
    "  â†“\n",
    "  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "  â†“                      â†“\n",
    "summarize_node      rag_retrieve_node (ë³‘ë ¬)\n",
    "  â†“                      â†“\n",
    "  â†“              generate_suggestion_node\n",
    "  â†“                      â†“\n",
    "  â””â”€â”€â”€â”€â”€â”€â†’ aggregate_node â†â”€â”€\n",
    "               â†“\n",
    "              END\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ytccvddnm8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# ì´ˆê¸° ìƒíƒœ ìƒì„±\n",
    "initial_state: ConversationState = {\n",
    "    \"session_id\": \"test-session-001\",\n",
    "    \"is_streaming\": True,\n",
    "    \"audio_chunks\": [b\"fake_audio_data_1\"],\n",
    "    \"chunk_timestamps\": [time.time()],\n",
    "    \"transcription\": \"\",\n",
    "    \"full_transcript\": [],\n",
    "    \"current_summary\": \"\",\n",
    "    \"query\": \"\",\n",
    "    \"retrieved_docs\": [],\n",
    "    \"suggestion\": \"\",\n",
    "    \"timestamp\": time.time(),\n",
    "    \"speaker\": \"customer\"\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸš€ ê·¸ë˜í”„ ì‹¤í–‰ ì‹œì‘\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹¤í–‰\n",
    "result = graph.invoke(initial_state)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… ê·¸ë˜í”„ ì‹¤í–‰ ì™„ë£Œ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\nğŸ“‹ ìµœì¢… ê²°ê³¼:\")\n",
    "print(f\"  ì „ì‚¬: {result['transcription']}\")\n",
    "print(f\"  ìš”ì•½: {result['current_summary']}\")\n",
    "print(f\"  ì¶”ì²œ: {result['suggestion']}\")\n",
    "print(f\"  ê²€ìƒ‰ëœ ë¬¸ì„œ: {len(result['retrieved_docs'])}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gs5n5lxas7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 6. ê·¸ë˜í”„ ì‹œê°í™” (ì„ íƒì )\n",
    "# ============================================\n",
    "\n",
    "try:\n",
    "    from IPython.display import Image, display\n",
    "    \n",
    "    # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±\n",
    "    graph_image = app.get_graph().draw_mermaid_png()\n",
    "    \n",
    "    # ì´ë¯¸ì§€ í‘œì‹œ\n",
    "    display(Image(graph_image))\n",
    "    print(\"âœ… ê·¸ë˜í”„ ì‹œê°í™” ì™„ë£Œ\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ì‹œê°í™” ì‹¤íŒ¨: {e}\")\n",
    "    print(\"   ëŒ€ì•ˆ: app.get_graph().print_ascii() ì‚¬ìš©\")\n",
    "    print(\"\\n\" + app.get_graph().print_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bw56f8sefsp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 7. ë‹¤ì¤‘ ì²­í¬ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜\n",
    "# ============================================\n",
    "\n",
    "print(\"ğŸ” ë‹¤ì¤‘ ì²­í¬ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜ (3íšŒ)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ì´ˆê¸° ìƒíƒœ\n",
    "state = {\n",
    "    \"session_id\": \"test-session-002\",\n",
    "    \"is_streaming\": True,\n",
    "    \"audio_chunks\": [],\n",
    "    \"chunk_timestamps\": [],\n",
    "    \"transcription\": \"\",\n",
    "    \"full_transcript\": [],\n",
    "    \"current_summary\": \"\",\n",
    "    \"query\": \"\",\n",
    "    \"retrieved_docs\": [],\n",
    "    \"suggestion\": \"\",\n",
    "    \"timestamp\": time.time(),\n",
    "    \"speaker\": \"customer\"\n",
    "}\n",
    "\n",
    "# 3ê°œ ì²­í¬ ìˆœì°¨ ì²˜ë¦¬\n",
    "for i in range(3):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ“¦ ì²­í¬ #{i+1} ì²˜ë¦¬ ì¤‘...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # ìƒˆ ì˜¤ë””ì˜¤ ì²­í¬ ì¶”ê°€\n",
    "    state[\"audio_chunks\"].append(f\"audio_chunk_{i+1}\".encode())\n",
    "    state[\"chunk_timestamps\"].append(time.time())\n",
    "    \n",
    "    # ê·¸ë˜í”„ ì‹¤í–‰\n",
    "    state = app.invoke(state)\n",
    "    \n",
    "    # ì§„í–‰ ìƒí™© ì¶œë ¥\n",
    "    print(f\"\\n  ì „ì‚¬ íˆìŠ¤í† ë¦¬: {len(state['full_transcript'])}ê°œ\")\n",
    "    print(f\"  ìµœì‹  ì „ì‚¬: {state['transcription']}\")\n",
    "    print(f\"  í˜„ì¬ ìš”ì•½: {state['current_summary']}\")\n",
    "    print(f\"  ìµœì‹  ì¶”ì²œ: {state['suggestion']}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"âœ… ë‹¤ì¤‘ ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nğŸ“Š ìµœì¢… í†µê³„:\")\n",
    "print(f\"  ì²˜ë¦¬í•œ ì²­í¬: {len(state['audio_chunks'])}ê°œ\")\n",
    "print(f\"  ì „ì‚¬ íˆìŠ¤í† ë¦¬: {len(state['full_transcript'])}ê°œ\")\n",
    "print(f\"  ìµœì¢… ìš”ì•½: {state['current_summary']}\")\n",
    "print(f\"  ìµœì¢… ì¶”ì²œ: {state['suggestion']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vr5b7wb730l",
   "metadata": {},
   "source": [
    "# ğŸ“ ë‹¤ìŒ êµ¬í˜„ ë‹¨ê³„\n",
    "\n",
    "## í˜„ì¬ ìƒíƒœ\n",
    "âœ… LangGraph êµ¬ì¡° ì™„ì„± (ë³‘ë ¬ ì²˜ë¦¬ í¬í•¨)  \n",
    "âœ… State ì •ì˜ ì™„ë£Œ  \n",
    "âœ… 5ê°œ ë…¸ë“œ Placeholder êµ¬í˜„  \n",
    "â³ WebSocket ì„œë²„ (ë¯¸êµ¬í˜„)  \n",
    "â³ ì‹¤ì œ STT/LLM/RAG í†µí•© (ë¯¸êµ¬í˜„)\n",
    "\n",
    "---\n",
    "\n",
    "## êµ¬í˜„í•´ì•¼ í•  ê¸°ëŠ¥\n",
    "\n",
    "### 1. ë…¸ë“œ ì‹¤ì œ êµ¬í˜„\n",
    "- **transcribe_node**: STT API í†µí•© (Google Cloud STT, Deepgram, Whisper)\n",
    "- **summarize_node**: LLM ìš”ì•½ (OpenAI, Anthropic, Ollama)\n",
    "- **rag_retrieve_node**: Vector DB ê²€ìƒ‰ (Pinecone, Chroma, FAISS)\n",
    "- **generate_suggestion_node**: LLM ìƒì„± (RAG ê¸°ë°˜)\n",
    "\n",
    "### 2. WebSocket ì„œë²„\n",
    "```python\n",
    "# FastAPI WebSocket Handler\n",
    "@app.websocket(\"/stt\")\n",
    "async def websocket_endpoint(websocket: WebSocket):\n",
    "    # ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹ \n",
    "    # LangGraph Agent ì‹¤í–‰\n",
    "    # ì‹¤ì‹œê°„ ê²°ê³¼ í‘¸ì‹œ\n",
    "```\n",
    "\n",
    "### 3. í´ë¼ì´ì–¸íŠ¸ (JavaScript)\n",
    "```javascript\n",
    "// AudioWorkletìœ¼ë¡œ ì˜¤ë””ì˜¤ ì¶”ì¶œ\n",
    "// WebSocketìœ¼ë¡œ ì„œë²„ ì „ì†¡\n",
    "// ì‹¤ì‹œê°„ ê²°ê³¼ ìˆ˜ì‹  ë° UI ì—…ë°ì´íŠ¸\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ë³‘ë ¬ ì²˜ë¦¬ í™•ì¸\n",
    "í˜„ì¬ ê·¸ë˜í”„ëŠ” **transcribe â†’ [summarize || rag_retrieve]** êµ¬ì¡°ë¡œ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì‹¤í–‰ íë¦„:\n",
    "1. transcribe_node ì‹¤í–‰\n",
    "2. **ë³‘ë ¬ ë¶„ê¸°**: summarize_node & rag_retrieve_node ë™ì‹œ ì‹¤í–‰\n",
    "3. generate_suggestion_node ì‹¤í–‰ (rag_retrieve ê²°ê³¼ ì‚¬ìš©)\n",
    "4. **Barrier**: aggregate_nodeê°€ ëª¨ë“  ê²°ê³¼ ëŒ€ê¸°\n",
    "5. í†µí•© ê²°ê³¼ ë°˜í™˜\n",
    "\n",
    "---\n",
    "\n",
    "## í…ŒìŠ¤íŠ¸ ë°©ë²•\n",
    "```python\n",
    "# ë‹¨ì¼ ì²­í¬ í…ŒìŠ¤íŠ¸\n",
    "result = app.invoke(initial_state)\n",
    "\n",
    "# ë‹¤ì¤‘ ì²­í¬ í…ŒìŠ¤íŠ¸ (ìœ„ì˜ ì…€ 7 ì‹¤í–‰)\n",
    "# ê° ì²­í¬ë§ˆë‹¤ ê·¸ë˜í”„ê°€ ì‹¤í–‰ë˜ë©° ìƒíƒœê°€ ëˆ„ì ë©ë‹ˆë‹¤\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "realtime-counselor-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
