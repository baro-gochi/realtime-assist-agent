"""Room-based Agent Manager for Real-time Conversation Summarization.

ì´ ëª¨ë“ˆì€ ë°©(room)ë³„ë¡œ LangGraph ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
    - ê° ë°©ë§ˆë‹¤ ë…ë¦½ì ì¸ ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìœ ì§€
    - ìƒˆë¡œìš´ transcript ìˆ˜ì‹  ì‹œ ì—ì´ì „íŠ¸ ì‹¤í–‰ (ë¹„ìŠ¤íŠ¸ë¦¬ë°)
    - ì¦ë¶„ ìš”ì•½: last_summarized_indexë¡œ ìš”ì•½ëœ ìœ„ì¹˜ ì¶”ì 
    - JSON í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ìš”ì•½ ë°˜í™˜
    - LLM ì¸ìŠ¤í„´ìŠ¤ë¥¼ í•œ ë²ˆë§Œ ì´ˆê¸°í™”í•˜ì—¬ ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ê³µìœ 

Architecture:
    - room_agents: {room_name: RoomAgent}
    - RoomAgent: ë°© í•˜ë‚˜ë‹¹ 1ê°œ ì¸ìŠ¤í„´ìŠ¤, State ìœ ì§€
    - llm: ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ê³µìœ í•˜ëŠ” LLM ì¸ìŠ¤í„´ìŠ¤ (ì„±ëŠ¥ ìµœì í™”)
    - ì¦ë¶„ ìš”ì•½: ê¸°ì¡´ ìš”ì•½ + ìƒˆë¡œìš´ transcriptë§Œ ì²˜ë¦¬

Example:
    >>> agent = get_or_create_agent("ìƒë‹´ì‹¤1")
    >>> result = await agent.on_new_transcript("ê³ ê°", "ê¹€ì² ìˆ˜", "í™˜ë¶ˆí•˜ê³  ì‹¶ì–´ìš”")
    >>> print(result)  # {"current_summary": '{"summary": "...", ...}', "last_summarized_index": 1}
"""
import os
import logging
import time
from typing import Dict, Any
from agent import create_agent_graph, ConversationState
from langchain.chat_models import init_chat_model
from dotenv import load_dotenv

logger = logging.getLogger(__name__)

load_dotenv()

# LLM ëª¨ë¸ ì„¤ì • (ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ê³µìœ )
LLM_MODEL = "openai:gpt-5-nano"



class RoomAgent:
    """ë°© í•˜ë‚˜ë‹¹ í•˜ë‚˜ì˜ ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤.

    ê° ìƒë‹´ ë°©ë§ˆë‹¤ ë…ë¦½ì ì¸ ëŒ€í™” íˆìŠ¤í† ë¦¬ì™€ ìš”ì•½ì„ ìœ ì§€í•©ë‹ˆë‹¤.

    Attributes:
        room_name (str): ë°© ì´ë¦„
        graph: ì»´íŒŒì¼ëœ LangGraph ì¸ìŠ¤í„´ìŠ¤
        state (ConversationState): í˜„ì¬ ëŒ€í™” ìƒíƒœ
    """

    def __init__(self, room_name: str):
        """RoomAgent ì´ˆê¸°í™”.

        Args:
            room_name (str): ë°© ì´ë¦„
        """
        # LLM ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™” (í´ë˜ìŠ¤ ìƒì„± ì‹œ ì‹¤í–‰)
        logger.info(f"ğŸ¤– Initializing LLM: {LLM_MODEL}")

        try:
            # TTFT ìµœì í™”: temperature=0 (Greedy Search)
            # - temperature=0: ê°€ì¥ í™•ë¥  ë†’ì€ í† í°ë§Œ ì„ íƒí•˜ì—¬ ìƒ˜í”Œë§ ì‹œê°„ ìµœì†Œí™”
            # - max_completion_tokens=150: GPT-5ì—ì„œëŠ” max_tokens ëŒ€ì‹  ì´ê±¸ ì‚¬ìš©
            # - reasoning_effort="minimal": ê°„ë‹¨í•œ ìš”ì•½ì—ëŠ” minimal reasoningìœ¼ë¡œ ë¹ ë¥´ê²Œ
            # - streaming=True: ì²« í† í° ì¦‰ì‹œ ë°˜í™˜
            llm = init_chat_model(
                LLM_MODEL,
                temperature=0,
                max_completion_tokens=150,
                reasoning_effort="minimal",
                streaming=True
            )

            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ (Runtime Contextë¡œ ì „ë‹¬í•  ë‚´ìš©) - JSON ì¶œë ¥ ê°•ì œ, í•œ ë¬¸ì¥ ìš”ì•½ ê°•ì¡°
            self.system_message = """
            # ì—­í• 
            ê³ ê° ìƒë‹´ ëŒ€í™”ë¥¼ ìš”ì•½í•˜ì—¬ ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
            ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.

            # ì¤‘ìš” ê·œì¹™
            - summary í•„ë“œëŠ” ë°˜ë“œì‹œ í•œ ë¬¸ì¥ì´ì–´ì•¼ í•©ë‹ˆë‹¤ (20ì ì´ë‚´)
            - ì´ì „ ìš”ì•½ì„ ì°¸ê³ í•˜ì§€ ë§ê³  í˜„ì¬ ëŒ€í™”ë§Œ ìš”ì•½í•˜ì„¸ìš”

            {{"summary": "í•œ ë¬¸ì¥ ìš”ì•½ (20ì ì´ë‚´)", "customer_issue": "ê³ ê° ë¬¸ì˜ í•œ ì¤„", "agent_action": "ìƒë‹´ì‚¬ ëŒ€ì‘ í•œ ì¤„"}}
            # ì˜ˆì‹œ:
            {{"summary": "ê³ ê°ì´ í™˜ë¶ˆì„ ìš”ì²­í•¨", "customer_issue": "ì œí’ˆ ë¶ˆëŸ‰ìœ¼ë¡œ í™˜ë¶ˆ ìš”ì²­", "agent_action": "í™˜ë¶ˆ ì ˆì°¨ ì•ˆë‚´"}}
            """

            logger.info("âœ… LLM initialized successfully")
        except Exception as e:
            logger.error(f"âŒ LLM initialization failed: {e}")
            llm = None
            self.system_message = None

        self.room_name = room_name
        self.llm_available = llm is not None

        if self.llm_available:
            self.graph = create_agent_graph(llm)
        else:
            self.graph = None
            logger.warning(f"âš ï¸ RoomAgent for '{room_name}' created without LLM - summaries will not be generated")

        self.state: ConversationState = {
            "room_name": room_name,
            "conversation_history": [],
            "current_summary": "",
            "last_summarized_index": 0,  # ì¦ë¶„ ìš”ì•½ìš© ì¸ë±ìŠ¤ ì¶”ì 
            "messages": []  # MessagesState í•„ìˆ˜ í•„ë“œ
        }

        logger.info(f"ğŸ¤– RoomAgent created for room: {room_name}")

    async def on_new_transcript(
        self,
        speaker_id: str,
        speaker_name: str,
        text: str,
        timestamp: float = None
    ) -> Dict[str, Any]:
        """ìƒˆë¡œìš´ transcriptë¥¼ ë°›ì•„ ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤ (ë¹„ìŠ¤íŠ¸ë¦¬ë°).

        Args:
            speaker_id (str): ë°œí™”ì ID (peer_id)
            speaker_name (str): ë°œí™”ì ì´ë¦„ (nickname)
            text (str): ì „ì‚¬ëœ í…ìŠ¤íŠ¸
            timestamp (float, optional): íƒ€ì„ìŠ¤íƒ¬í”„. Noneì´ë©´ í˜„ì¬ ì‹œê°„ ì‚¬ìš©

        Returns:
            Dict[str, Any]: {"current_summary": str (JSON), "last_summarized_index": int}
                           ë˜ëŠ” ì—ëŸ¬ ì‹œ {"error": {"message": str}}

        Example:
            >>> result = await agent.on_new_transcript("peer123", "ê¹€ì² ìˆ˜", "í™˜ë¶ˆí•˜ê³  ì‹¶ì–´ìš”")
            >>> print(result)
            {"current_summary": '{"summary": "...", "customer_issue": "...", "agent_action": "..."}', ...}
        """
        if timestamp is None:
            timestamp = time.time()

        # Stateì— ìƒˆ transcript ì¶”ê°€
        self.state["conversation_history"].append({
            "speaker_id": speaker_id,
            "speaker_name": speaker_name,
            "text": text,
            "timestamp": timestamp
        })

        logger.info(
            f"ğŸ“ New transcript in room '{self.room_name}': "
            f"{speaker_name}: {text[:50]}..."
        )
        logger.info(f"ğŸ“Š Current conversation history count: {len(self.state['conversation_history'])}")

        # LLM ì—†ìœ¼ë©´ ìš”ì•½ ìƒì„± ìŠ¤í‚µ (transcriptëŠ” ì´ë¯¸ ì¶”ê°€ë¨)
        if not self.llm_available:
            logger.warning(f"âš ï¸ LLM not available - skipping summary generation for room '{self.room_name}'")
            return {"error": {"message": "LLM not available"}}

        # LangGraph ë¹„ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰ (Runtime Contextë¡œ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì „ë‹¬)
        logger.info(f"ğŸš€ Starting graph.ainvoke for room '{self.room_name}'")

        try:
            # ainvokeë¡œ í•œ ë²ˆì— ê²°ê³¼ ë°›ê¸° (ë¹„ìŠ¤íŠ¸ë¦¬ë°)
            result = await self.graph.ainvoke(
                self.state,
                context={"system_message": self.system_message}  # Runtime Context ì „ë‹¬
            )

            # ê²°ê³¼ì—ì„œ ìš”ì•½ ë° ì¸ë±ìŠ¤ ì¶”ì¶œ
            current_summary = result.get("current_summary", "")
            last_summarized_index = result.get("last_summarized_index", 0)

            # State ì—…ë°ì´íŠ¸
            self.state["current_summary"] = current_summary
            self.state["last_summarized_index"] = last_summarized_index

            logger.info(f"âœ… Summary generated (JSON): {current_summary[:100]}...")
            logger.info(f"ğŸ“Š Last summarized index: {last_summarized_index}")

            return {
                "current_summary": current_summary,
                "last_summarized_index": last_summarized_index
            }

        except Exception as e:
            logger.error(f"âŒ Error in agent execution: {e}", exc_info=True)
            return {"error": {"message": str(e)}}

    def get_current_summary(self) -> str:
        """í˜„ì¬ ëŒ€í™” ìš”ì•½ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

        Returns:
            str: í˜„ì¬ê¹Œì§€ì˜ ëŒ€í™” ìš”ì•½
        """
        return self.state.get("current_summary", "")

    def get_conversation_count(self) -> int:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ê°œìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

        Returns:
            int: ëˆ„ì ëœ ëŒ€í™” ê°œìˆ˜
        """
        return len(self.state.get("conversation_history", []))

    def reset(self):
        """ì—ì´ì „íŠ¸ ìƒíƒœë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        Note:
            ë°©ì´ ì¢…ë£Œë˜ê±°ë‚˜ ìƒˆë¡œìš´ ì„¸ì…˜ì„ ì‹œì‘í•  ë•Œ ì‚¬ìš©
        """
        logger.info(f"ğŸ”„ Resetting agent for room: {self.room_name}")
        self.state = {
            "room_name": self.room_name,
            "conversation_history": [],
            "current_summary": "",
            "last_summarized_index": 0,  # ì¦ë¶„ ìš”ì•½ìš© ì¸ë±ìŠ¤ ì´ˆê¸°í™”
            "messages": []  # MessagesState í•„ìˆ˜ í•„ë“œ
        }


# ê¸€ë¡œë²Œ ì—ì´ì „íŠ¸ ì €ì¥ì†Œ
# {room_name: RoomAgent}
room_agents: Dict[str, RoomAgent] = {}


def get_or_create_agent(room_name: str) -> RoomAgent:
    """ë°© ì´ë¦„ì— í•´ë‹¹í•˜ëŠ” ì—ì´ì „íŠ¸ë¥¼ ë°˜í™˜í•˜ê±°ë‚˜ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        room_name (str): ë°© ì´ë¦„

    Returns:
        RoomAgent: í•´ë‹¹ ë°©ì˜ ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤

    Note:
        - ë°© ì…ì¥ ì‹œ ìë™ìœ¼ë¡œ ì—ì´ì „íŠ¸ ìƒì„±
        - ì´ë¯¸ ì¡´ì¬í•˜ë©´ ê¸°ì¡´ ì¸ìŠ¤í„´ìŠ¤ ì¬ì‚¬ìš©
    """
    if room_name not in room_agents:
        agent = RoomAgent(room_name)
        room_agents[room_name] = agent
        logger.info(f"âœ… New agent created for room: {room_name}")
    else:
        logger.debug(f"â™»ï¸ Reusing existing agent for room: {room_name}")

    return room_agents[room_name]


def remove_agent(room_name: str):
    """ë°©ì˜ ì—ì´ì „íŠ¸ë¥¼ ì œê±°í•©ë‹ˆë‹¤.

    Args:
        room_name (str): ë°© ì´ë¦„

    Note:
        - ë°©ì´ ì™„ì „íˆ ì¢…ë£Œë  ë•Œ í˜¸ì¶œ
        - ë©”ëª¨ë¦¬ ì •ë¦¬ ëª©ì 
    """
    if room_name in room_agents:
        del room_agents[room_name]
        logger.info(f"ğŸ—‘ï¸ Agent removed for room: {room_name}")
    else:
        logger.warning(f"âš ï¸ No agent found for room: {room_name}")


def get_all_agents() -> Dict[str, RoomAgent]:
    """ëª¨ë“  í™œì„± ì—ì´ì „íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Returns:
        Dict[str, RoomAgent]: {room_name: RoomAgent}

    Note:
        ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹… ëª©ì 
    """
    return room_agents.copy()
