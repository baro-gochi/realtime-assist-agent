"""Room-based Agent Manager for Real-time Conversation Summarization.

ì´ ëª¨ë“ˆì€ ë°©(room)ë³„ë¡œ LangGraph ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
    - ê° ë°©ë§ˆë‹¤ ë…ë¦½ì ì¸ ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìœ ì§€
    - ìƒˆë¡œìš´ transcript ìˆ˜ì‹  ì‹œ ì—ì´ì „íŠ¸ ì‹¤í–‰
    - ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¡œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ë°˜í™˜
    - LLM ì¸ìŠ¤í„´ìŠ¤ë¥¼ í•œ ë²ˆë§Œ ì´ˆê¸°í™”í•˜ì—¬ ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ê³µìœ 

Architecture:
    - room_agents: {room_name: RoomAgent}
    - RoomAgent: ë°© í•˜ë‚˜ë‹¹ 1ê°œ ì¸ìŠ¤í„´ìŠ¤, State ìœ ì§€
    - llm: ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ê³µìœ í•˜ëŠ” LLM ì¸ìŠ¤í„´ìŠ¤ (ì„±ëŠ¥ ìµœì í™”)

Example:
    >>> agent = get_or_create_agent("ìƒë‹´ì‹¤1")
    >>> async for chunk in agent.on_new_transcript("ê³ ê°", "ê¹€ì² ìˆ˜", "í™˜ë¶ˆí•˜ê³  ì‹¶ì–´ìš”"):
    ...     print(chunk)  # {"summarize": {"current_summary": "..."}}
"""
import os
import logging
import time
from typing import Dict, AsyncIterator, Any
from agent import create_agent_graph, ConversationState
from langchain.chat_models import init_chat_model
from dotenv import load_dotenv

logger = logging.getLogger(__name__)

load_dotenv()

# LLM ëª¨ë¸ ì„¤ì • (ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ê³µìœ )
LLM_MODEL = "openai:gpt-5-nano"



class RoomAgent:
    """ë°© í•˜ë‚˜ë‹¹ í•˜ë‚˜ì˜ ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤.

    ê° ìƒë‹´ ë°©ë§ˆë‹¤ ë…ë¦½ì ì¸ ëŒ€í™” íˆìŠ¤í† ë¦¬ì™€ ìš”ì•½ì„ ìœ ì§€í•©ë‹ˆë‹¤.

    Attributes:
        room_name (str): ë°© ì´ë¦„
        graph: ì»´íŒŒì¼ëœ LangGraph ì¸ìŠ¤í„´ìŠ¤
        state (ConversationState): í˜„ì¬ ëŒ€í™” ìƒíƒœ
    """

    def __init__(self, room_name: str):
        """RoomAgent ì´ˆê¸°í™”.

        Args:
            room_name (str): ë°© ì´ë¦„
        """
        # LLM ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™” (í´ë˜ìŠ¤ ìƒì„± ì‹œ ì‹¤í–‰)
        logger.info(f"ğŸ¤– Initializing LLM: {LLM_MODEL}")

        try:
            # TTFT ìµœì í™”: temperature=0 (Greedy Search)
            # - temperature=0: ê°€ì¥ í™•ë¥  ë†’ì€ í† í°ë§Œ ì„ íƒí•˜ì—¬ ìƒ˜í”Œë§ ì‹œê°„ ìµœì†Œí™”
            # - max_completion_tokens=150: GPT-5ì—ì„œëŠ” max_tokens ëŒ€ì‹  ì´ê±¸ ì‚¬ìš©
            # - reasoning_effort="minimal": ê°„ë‹¨í•œ ìš”ì•½ì—ëŠ” minimal reasoningìœ¼ë¡œ ë¹ ë¥´ê²Œ
            # - streaming=True: ì²« í† í° ì¦‰ì‹œ ë°˜í™˜
            llm = init_chat_model(
                LLM_MODEL,
                temperature=0,
                max_completion_tokens=150,
                reasoning_effort="minimal",
                streaming=True
            )

            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ (Runtime Contextë¡œ ì „ë‹¬í•  ë‚´ìš©)
            self.system_message = """ê³ ê° ìƒë‹´ ëŒ€í™”ë¥¼ 1ë¬¸ì¥ìœ¼ë¡œ ê°œì¡°ì‹ìœ¼ë¡œ ë§¤ìš° ê°„ë‹¨í•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”.
ì˜ˆì‹œ: ê³ ê°ì´ í™˜ë¶ˆì„ ìš”ì²­í•¨.
ê³ ê°ì˜ ì£¼ìš” ë¬¸ì˜ì‚¬í•­ê³¼ ìƒë‹´ì‚¬ì˜ ëŒ€ì‘ì„ í¬í•¨í•˜ì„¸ìš”."""

            logger.info("âœ… LLM initialized successfully")
        except Exception as e:
            logger.error(f"âŒ LLM initialization failed: {e}")
            llm = None
            self.system_message = None

        self.room_name = room_name
        self.llm_available = llm is not None

        if self.llm_available:
            self.graph = create_agent_graph(llm)
        else:
            self.graph = None
            logger.warning(f"âš ï¸ RoomAgent for '{room_name}' created without LLM - summaries will not be generated")

        self.state: ConversationState = {
            "room_name": room_name,
            "conversation_history": [],
            "current_summary": "",
            "messages": []  # MessagesState í•„ìˆ˜ í•„ë“œ
        }

        logger.info(f"ğŸ¤– RoomAgent created for room: {room_name}")

    async def on_new_transcript(
        self,
        speaker_id: str,
        speaker_name: str,
        text: str,
        timestamp: float = None
    ) -> AsyncIterator[Dict[str, Any]]:
        """ìƒˆë¡œìš´ transcriptë¥¼ ë°›ì•„ ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

        Args:
            speaker_id (str): ë°œí™”ì ID (peer_id)
            speaker_name (str): ë°œí™”ì ì´ë¦„ (nickname)
            text (str): ì „ì‚¬ëœ í…ìŠ¤íŠ¸
            timestamp (float, optional): íƒ€ì„ìŠ¤íƒ¬í”„. Noneì´ë©´ í˜„ì¬ ì‹œê°„ ì‚¬ìš©

        Yields:
            Dict[str, Any]: {"node_name": {ì—…ë°ì´íŠ¸ëœ State ë¶€ë¶„}}

        Example:
            >>> async for chunk in agent.on_new_transcript("peer123", "ê¹€ì² ìˆ˜", "í™˜ë¶ˆí•˜ê³  ì‹¶ì–´ìš”"):
            ...     print(chunk)
            {"summarize": {"current_summary": "ê³ ê°ì´ í™˜ë¶ˆì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤."}}
        """
        if timestamp is None:
            timestamp = time.time()

        # Stateì— ìƒˆ transcript ì¶”ê°€
        self.state["conversation_history"].append({
            "speaker_id": speaker_id,
            "speaker_name": speaker_name,
            "text": text,
            "timestamp": timestamp
        })

        logger.info(
            f"ğŸ“ New transcript in room '{self.room_name}': "
            f"{speaker_name}: {text[:50]}..."
        )
        logger.info(f"ğŸ“Š Current conversation history count: {len(self.state['conversation_history'])}")

        # LLM ì—†ìœ¼ë©´ ìš”ì•½ ìƒì„± ìŠ¤í‚µ (transcriptëŠ” ì´ë¯¸ ì¶”ê°€ë¨)
        if not self.llm_available:
            logger.warning(f"âš ï¸ LLM not available - skipping summary generation for room '{self.room_name}'")
            return

        # LangGraph ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰ (Runtime Contextë¡œ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì „ë‹¬)
        # stream_mode="messages": LLMì˜ ê° í† í°ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°
        logger.info(f"ğŸš€ Starting graph.astream for room '{self.room_name}'")
        summary_chunks = []  # ìš”ì•½ ì²­í¬ë¥¼ ëˆ„ì 

        try:
            async for chunk in self.graph.astream(
                self.state,
                stream_mode="messages",  # LLM ë©”ì‹œì§€ ìŠ¤íŠ¸ë¦¬ë°
                context={"system_message": self.system_message}  # Runtime Context ì „ë‹¬
            ):
                # chunkëŠ” (message, metadata) íŠœí”Œ í˜•íƒœ
                message, metadata = chunk
                logger.debug(f"ğŸ“¤ Message chunk received: {message}")

                # AIMessageì˜ contentë§Œ ì¶”ì¶œ
                if hasattr(message, 'content') and message.content:
                    content = message.content
                    summary_chunks.append(content)

                    # í˜„ì¬ê¹Œì§€ ëˆ„ì ëœ ìš”ì•½ì„ Stateì— ë°˜ì˜
                    current_summary = "".join(summary_chunks)
                    self.state["current_summary"] = current_summary

                    # ê° ì²­í¬ë¥¼ ì¦‰ì‹œ yield (í”„ë¡ íŠ¸ì—”ë“œë¡œ ìŠ¤íŠ¸ë¦¬ë°)
                    yield {
                        "summarize": {
                            "current_summary": current_summary,
                            "is_streaming": True  # ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì„ì„ í‘œì‹œ
                        }
                    }

            # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í‘œì‹œ
            if summary_chunks:
                final_summary = "".join(summary_chunks)
                self.state["current_summary"] = final_summary
                yield {
                    "summarize": {
                        "current_summary": final_summary,
                        "is_streaming": False  # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ
                    }
                }

        except Exception as e:
            logger.error(f"âŒ Error in agent execution: {e}", exc_info=True)
            # ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ë¹ˆ ì—…ë°ì´íŠ¸ ë°˜í™˜ (í´ë¼ì´ì–¸íŠ¸ê°€ ë©ˆì¶”ì§€ ì•Šë„ë¡)
            yield {"error": {"message": str(e)}}

    def get_current_summary(self) -> str:
        """í˜„ì¬ ëŒ€í™” ìš”ì•½ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

        Returns:
            str: í˜„ì¬ê¹Œì§€ì˜ ëŒ€í™” ìš”ì•½
        """
        return self.state.get("current_summary", "")

    def get_conversation_count(self) -> int:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ê°œìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

        Returns:
            int: ëˆ„ì ëœ ëŒ€í™” ê°œìˆ˜
        """
        return len(self.state.get("conversation_history", []))

    def reset(self):
        """ì—ì´ì „íŠ¸ ìƒíƒœë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        Note:
            ë°©ì´ ì¢…ë£Œë˜ê±°ë‚˜ ìƒˆë¡œìš´ ì„¸ì…˜ì„ ì‹œì‘í•  ë•Œ ì‚¬ìš©
        """
        logger.info(f"ğŸ”„ Resetting agent for room: {self.room_name}")
        self.state = {
            "room_name": self.room_name,
            "conversation_history": [],
            "current_summary": "",
            "messages": []  # MessagesState í•„ìˆ˜ í•„ë“œ
        }


# ê¸€ë¡œë²Œ ì—ì´ì „íŠ¸ ì €ì¥ì†Œ
# {room_name: RoomAgent}
room_agents: Dict[str, RoomAgent] = {}


def get_or_create_agent(room_name: str) -> RoomAgent:
    """ë°© ì´ë¦„ì— í•´ë‹¹í•˜ëŠ” ì—ì´ì „íŠ¸ë¥¼ ë°˜í™˜í•˜ê±°ë‚˜ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        room_name (str): ë°© ì´ë¦„

    Returns:
        RoomAgent: í•´ë‹¹ ë°©ì˜ ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤

    Note:
        - ë°© ì…ì¥ ì‹œ ìë™ìœ¼ë¡œ ì—ì´ì „íŠ¸ ìƒì„±
        - ì´ë¯¸ ì¡´ì¬í•˜ë©´ ê¸°ì¡´ ì¸ìŠ¤í„´ìŠ¤ ì¬ì‚¬ìš©
    """
    if room_name not in room_agents:
        agent = RoomAgent(room_name)
        room_agents[room_name] = agent
        logger.info(f"âœ… New agent created for room: {room_name}")
    else:
        logger.debug(f"â™»ï¸ Reusing existing agent for room: {room_name}")

    return room_agents[room_name]


def remove_agent(room_name: str):
    """ë°©ì˜ ì—ì´ì „íŠ¸ë¥¼ ì œê±°í•©ë‹ˆë‹¤.

    Args:
        room_name (str): ë°© ì´ë¦„

    Note:
        - ë°©ì´ ì™„ì „íˆ ì¢…ë£Œë  ë•Œ í˜¸ì¶œ
        - ë©”ëª¨ë¦¬ ì •ë¦¬ ëª©ì 
    """
    if room_name in room_agents:
        del room_agents[room_name]
        logger.info(f"ğŸ—‘ï¸ Agent removed for room: {room_name}")
    else:
        logger.warning(f"âš ï¸ No agent found for room: {room_name}")


def get_all_agents() -> Dict[str, RoomAgent]:
    """ëª¨ë“  í™œì„± ì—ì´ì „íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Returns:
        Dict[str, RoomAgent]: {room_name: RoomAgent}

    Note:
        ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹… ëª©ì 
    """
    return room_agents.copy()
