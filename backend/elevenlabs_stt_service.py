"""ElevenLabs Speech-to-Text ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤ ëª¨ë“ˆ.

ì´ ëª¨ë“ˆì€ ElevenLabs Speech-to-Text APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„
í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
    - ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì¸ì‹ (WebSocket Streaming)
    - WebRTC ì˜¤ë””ì˜¤ í”„ë ˆì„ì„ ElevenLabs API í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    - ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ í†µí•œ ë†’ì€ ì²˜ë¦¬ëŸ‰
    - í•œêµ­ì–´ ìŒì„± ì¸ì‹ ì§€ì›

Architecture:
    - ElevenLabs Scribe v2 Realtime ëª¨ë¸ ì‚¬ìš©
    - WebSocket ê¸°ë°˜ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°
    - AudioFrame â†’ PCM bytes â†’ Base64 ë³€í™˜ íŒŒì´í”„ë¼ì¸
    - Partial/Committed transcript ì§€ì›

Examples:
    ê¸°ë³¸ ì‚¬ìš©ë²•:
        >>> service = ElevenLabsSTTService()
        >>> async for text in service.process_audio_stream(audio_frames):
        ...     print(f"ì¸ì‹ëœ í…ìŠ¤íŠ¸: {text}")

See Also:
    ElevenLabs STT Docs: https://elevenlabs.io/docs/capabilities/speech-to-text
"""
import asyncio
import base64
import json
import logging
import os
import time
from typing import AsyncIterator, Optional

import numpy as np
import websockets
from av import AudioFrame

logger = logging.getLogger(__name__)


class ElevenLabsSTTService:
    """ElevenLabs Speech-to-Text ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤ í´ë˜ìŠ¤.

    WebRTC ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    WebSocket ê¸°ë°˜ Scribe v2 Realtime ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

    Attributes:
        api_key (str): ElevenLabs API í‚¤
        model_id (str): ì‚¬ìš©í•  STT ëª¨ë¸ ID
        language_code (str): ìŒì„± ì¸ì‹ ì–¸ì–´ ì½”ë“œ
        sample_rate (int): ì¶œë ¥ ìƒ˜í”Œë ˆì´íŠ¸ (16kHz)

    Note:
        - ELEVENLABS_API_KEY í™˜ê²½ ë³€ìˆ˜ í•„ìˆ˜
        - WebRTC 48kHz ì˜¤ë””ì˜¤ë¥¼ 16kHzë¡œ ë¦¬ìƒ˜í”Œë§
        - PCM 16-bit mono í¬ë§· ì‚¬ìš©
        - VAD ëª¨ë“œë¡œ ìë™ ì»¤ë°‹ í™œì„±í™”
    """

    # ElevenLabs WebSocket endpoint
    WS_URL = "wss://api.elevenlabs.io/v1/speech-to-text/realtime"
    MODEL_ID = "scribe_v2_realtime"
    TARGET_SAMPLE_RATE = 16000  # ElevenLabs ê¶Œì¥ ìƒ˜í”Œë ˆì´íŠ¸

    # VAD (Voice Activity Detection) ì„¤ì •
    COMMIT_STRATEGY = "vad"  # "manual" or "vad" - VADë¡œ ìë™ ì»¤ë°‹
    VAD_SILENCE_THRESHOLD_SECS = 0.5  # ì¹¨ë¬µ ê°ì§€ ì‹œê°„ (ì´ˆ) - ì§§ì„ìˆ˜ë¡ ë¹ ë¥¸ ì‘ë‹µ
    VAD_THRESHOLD = 0.5  # VAD ê°ì§€ ì„ê³„ê°’

    def __init__(
        self,
        api_key: Optional[str] = None,
        language_code: str = "ko",
    ):
        """ElevenLabsSTTService ì´ˆê¸°í™”.

        Args:
            api_key (str, optional): ElevenLabs API í‚¤.
                í™˜ê²½ ë³€ìˆ˜ ELEVENLABS_API_KEY ì‚¬ìš© ê°€ëŠ¥
            language_code (str): ìŒì„± ì¸ì‹ ì–¸ì–´ ì½”ë“œ. ê¸°ë³¸ê°’ "ko" (í•œêµ­ì–´)

        Raises:
            ValueError: ELEVENLABS_API_KEY ë¯¸ì„¤ì • ì‹œ
        """
        self.api_key = api_key or os.getenv("ELEVENLABS_API_KEY")
        if not self.api_key:
            raise ValueError(
                "ELEVENLABS_API_KEY environment variable must be set"
            )

        self.language_code = language_code
        self.sample_rate = self.TARGET_SAMPLE_RATE

        logger.info(
            f"ElevenLabs STT Service initialized: "
            f"model={self.MODEL_ID}, "
            f"language={self.language_code}, "
            f"sample_rate={self.sample_rate}, "
            f"commit_strategy={self.COMMIT_STRATEGY}, "
            f"vad_silence={self.VAD_SILENCE_THRESHOLD_SECS}s"
        )

    def _resample_audio(self, audio_array: np.ndarray, orig_sr: int, target_sr: int) -> np.ndarray:
        """ì˜¤ë””ì˜¤ë¥¼ ëª©í‘œ ìƒ˜í”Œë ˆì´íŠ¸ë¡œ ë¦¬ìƒ˜í”Œë§í•©ë‹ˆë‹¤.

        ê°„ë‹¨í•œ ì„ í˜• ë³´ê°„ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

        Args:
            audio_array: ì›ë³¸ ì˜¤ë””ì˜¤ ë°°ì—´
            orig_sr: ì›ë³¸ ìƒ˜í”Œë ˆì´íŠ¸
            target_sr: ëª©í‘œ ìƒ˜í”Œë ˆì´íŠ¸

        Returns:
            ë¦¬ìƒ˜í”Œë§ëœ ì˜¤ë””ì˜¤ ë°°ì—´
        """
        if orig_sr == target_sr:
            return audio_array

        # ë¦¬ìƒ˜í”Œë§ ë¹„ìœ¨ ê³„ì‚°
        ratio = target_sr / orig_sr
        new_length = int(len(audio_array) * ratio)

        # ì„ í˜• ë³´ê°„ìœ¼ë¡œ ë¦¬ìƒ˜í”Œë§
        indices = np.linspace(0, len(audio_array) - 1, new_length)
        resampled = np.interp(indices, np.arange(len(audio_array)), audio_array)

        return resampled.astype(audio_array.dtype)

    def _audio_frame_to_base64(self, frame: AudioFrame) -> str:
        """AudioFrameì„ ElevenLabs API í˜•ì‹ì˜ Base64 ë¬¸ìì—´ë¡œ ë³€í™˜.

        WebRTC AudioFrameì„ 16-bit PCM â†’ Base64ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        48kHz â†’ 16kHz ë¦¬ìƒ˜í”Œë§ë„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        Args:
            frame (AudioFrame): WebRTC ì˜¤ë””ì˜¤ í”„ë ˆì„

        Returns:
            str: Base64 ì¸ì½”ë”©ëœ PCM ì˜¤ë””ì˜¤ ë°ì´í„°
        """
        # Convert AudioFrame to numpy array
        array = frame.to_ndarray()

        # Handle stereo to mono conversion
        if array.ndim > 1:
            array = array.flatten()

        # Check if stereo (2x samples for interleaved L-R-L-R)
        if array.size == frame.samples * 2:
            array = array.reshape(-1, 2).mean(axis=1).astype(array.dtype)

        # Convert float to int16 if needed
        if array.dtype in (np.float32, np.float64):
            array = (array * 32767).astype(np.int16)
        elif array.dtype == np.int16:
            # Apply gain to low volume audio
            max_val = np.abs(array).max()
            if max_val > 0 and max_val < 5000:
                gain = min(6500.0 / max_val, 20.0)
                array = np.clip(array * gain, -32768, 32767).astype(np.int16)

        # Resample from 48kHz to 16kHz
        if frame.sample_rate != self.TARGET_SAMPLE_RATE:
            array = self._resample_audio(array, frame.sample_rate, self.TARGET_SAMPLE_RATE)
            array = array.astype(np.int16)

        # Convert to bytes and Base64 encode
        audio_bytes = array.tobytes()
        return base64.b64encode(audio_bytes).decode('utf-8')

    async def process_audio_stream(
        self,
        audio_queue: asyncio.Queue
    ) -> AsyncIterator[dict]:
        """ì˜¤ë””ì˜¤ í”„ë ˆì„ íë¥¼ ì²˜ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜.

        ë¹„ë™ê¸° ì œë„ˆë ˆì´í„°ë¡œ ì—°ì†ì ì¸ ìŒì„± ì¸ì‹ ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.

        Args:
            audio_queue (asyncio.Queue): AudioFrame ê°ì²´ë¥¼ ë‹´ì€ ë¹„ë™ê¸° í

        Yields:
            dict: ì¸ì‹ ê²°ê³¼
                - text (str): ì¸ì‹ëœ í…ìŠ¤íŠ¸
                - is_final (bool): ìµœì¢… ê²°ê³¼ ì—¬ë¶€
                - latency_ms (float): ì‘ë‹µ ì§€ì—°ì‹œê°„ (ë°€ë¦¬ì´ˆ)

        Note:
            - íì—ì„œ Noneì„ ë°›ìœ¼ë©´ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ
            - WebSocket ì—°ê²° ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„
            - 0.1 ~ 1ì´ˆ ì²­í¬ ê¶Œì¥ (Best Practice)
            - VAD ëª¨ë“œë¡œ ìë™ ì»¤ë°‹í•˜ì—¬ committed_transcript ìˆ˜ì‹ 
        """
        # VAD íŒŒë¼ë¯¸í„° í¬í•¨í•˜ì—¬ WebSocket URL êµ¬ì„±
        ws_url = (
            f"{self.WS_URL}"
            f"?model_id={self.MODEL_ID}"
            f"&language_code={self.language_code}"
            f"&commit_strategy={self.COMMIT_STRATEGY}"
            f"&vad_silence_threshold_secs={self.VAD_SILENCE_THRESHOLD_SECS}"
            f"&vad_threshold={self.VAD_THRESHOLD}"
        )

        extra_headers = {
            "xi-api-key": self.api_key
        }

        logger.info(f"ğŸ”Œ Connecting to ElevenLabs STT WebSocket...")

        try:
            async with websockets.connect(
                ws_url,
                additional_headers=extra_headers,
                ping_interval=20,
                ping_timeout=10
            ) as ws:
                logger.info("âœ… ElevenLabs WebSocket connected")

                # Wait for session_started event
                init_response = await asyncio.wait_for(ws.recv(), timeout=10.0)
                init_data = json.loads(init_response)
                if init_data.get("message_type") == "session_started":
                    config = init_data.get("config", {})
                    vad_strategy = config.get("vad_commit_strategy", "unknown")
                    vad_silence = config.get("vad_silence_threshold_secs", "unknown")
                    logger.info(
                        f"âœ… ElevenLabs session started: "
                        f"vad_commit_strategy={vad_strategy}, "
                        f"vad_silence_threshold={vad_silence}s"
                    )
                else:
                    logger.warning(f"âš ï¸ Unexpected init message: {init_data}")

                # Task to send audio chunks
                send_task = asyncio.create_task(
                    self._send_audio_chunks(ws, audio_queue)
                )

                # Task to receive transcripts
                try:
                    async for result in self._receive_transcripts(ws):
                        yield result
                finally:
                    send_task.cancel()
                    try:
                        await send_task
                    except asyncio.CancelledError:
                        pass

        except websockets.exceptions.ConnectionClosed as e:
            logger.error(f"âŒ ElevenLabs WebSocket connection closed: {e}")
            raise
        except Exception as e:
            logger.error(f"âŒ ElevenLabs STT error: {e}", exc_info=True)
            raise

    async def _send_audio_chunks(
        self,
        ws: websockets.WebSocketClientProtocol,
        audio_queue: asyncio.Queue
    ):
        """ì˜¤ë””ì˜¤ ì²­í¬ë¥¼ WebSocketìœ¼ë¡œ ì „ì†¡í•©ë‹ˆë‹¤.

        Args:
            ws: WebSocket ì—°ê²°
            audio_queue: ì˜¤ë””ì˜¤ í”„ë ˆì„ í
        """
        chunk_count = 0
        accumulated_frames = []
        accumulated_duration = 0.0
        target_chunk_duration = 0.25  # 250ms ì²­í¬

        try:
            while True:
                frame = await audio_queue.get()
                if frame is None:
                    # Send remaining frames
                    if accumulated_frames:
                        await self._send_accumulated_frames(ws, accumulated_frames, chunk_count)
                    # Send commit signal
                    commit_msg = json.dumps({
                        "message_type": "input_audio_chunk",
                        "audio_base_64": "",
                        "commit": True,
                        "sample_rate": self.TARGET_SAMPLE_RATE
                    })
                    await ws.send(commit_msg)
                    logger.info(f"ğŸ ElevenLabs audio stream ended. Total chunks: {chunk_count}")
                    break

                # Accumulate frames for batching
                accumulated_frames.append(frame)
                frame_duration = frame.samples / frame.sample_rate
                accumulated_duration += frame_duration

                # Send when we have enough audio (250ms chunks)
                if accumulated_duration >= target_chunk_duration:
                    chunk_count += 1
                    if chunk_count == 1:
                        logger.info("ğŸ“¤ Sending first audio chunk to ElevenLabs...")

                    await self._send_accumulated_frames(ws, accumulated_frames, chunk_count)

                    # Reset accumulator
                    accumulated_frames = []
                    accumulated_duration = 0.0

                    # Log progress
                    if chunk_count % 40 == 0:  # Every ~10 seconds
                        logger.info(f"ğŸ“¦ Sent {chunk_count} chunks to ElevenLabs")

        except asyncio.CancelledError:
            logger.info("ğŸ“¡ ElevenLabs audio sender cancelled")
            raise
        except Exception as e:
            logger.error(f"âŒ Error sending audio to ElevenLabs: {e}", exc_info=True)
            raise

    async def _send_accumulated_frames(
        self,
        ws: websockets.WebSocketClientProtocol,
        frames: list,
        chunk_count: int
    ):
        """ëˆ„ì ëœ í”„ë ˆì„ë“¤ì„ í•˜ë‚˜ì˜ ì²­í¬ë¡œ ì „ì†¡í•©ë‹ˆë‹¤."""
        # Combine all frames into one audio buffer
        all_audio = []
        for frame in frames:
            array = frame.to_ndarray()
            if array.ndim > 1:
                array = array.flatten()
            if array.size == frame.samples * 2:
                array = array.reshape(-1, 2).mean(axis=1).astype(array.dtype)
            if array.dtype in (np.float32, np.float64):
                array = (array * 32767).astype(np.int16)
            elif array.dtype == np.int16:
                max_val = np.abs(array).max()
                if max_val > 0 and max_val < 5000:
                    gain = min(6500.0 / max_val, 20.0)
                    array = np.clip(array * gain, -32768, 32767).astype(np.int16)

            # Resample each frame
            if frame.sample_rate != self.TARGET_SAMPLE_RATE:
                array = self._resample_audio(array, frame.sample_rate, self.TARGET_SAMPLE_RATE)
                array = array.astype(np.int16)

            all_audio.append(array)

        # Concatenate all arrays
        combined_audio = np.concatenate(all_audio)
        audio_bytes = combined_audio.tobytes()
        audio_base64 = base64.b64encode(audio_bytes).decode('utf-8')

        # Send to ElevenLabs
        message = json.dumps({
            "message_type": "input_audio_chunk",
            "audio_base_64": audio_base64,
            "commit": False,
            "sample_rate": self.TARGET_SAMPLE_RATE
        })
        await ws.send(message)

        if chunk_count == 1:
            logger.info(f"ğŸ“¤ First chunk sent: {len(audio_bytes)} bytes, {len(frames)} frames")

    async def _receive_transcripts(
        self,
        ws: websockets.WebSocketClientProtocol
    ) -> AsyncIterator[dict]:
        """WebSocketì—ì„œ transcript ë©”ì‹œì§€ë¥¼ ìˆ˜ì‹ í•©ë‹ˆë‹¤.

        Args:
            ws: WebSocket ì—°ê²°

        Yields:
            dict: ì¸ì‹ ê²°ê³¼
        """
        last_send_time = time.time()

        try:
            async for message in ws:
                receive_time = time.time()
                data = json.loads(message)
                msg_type = data.get("message_type")

                if msg_type == "partial_transcript":
                    text = data.get("text", "")
                    if text.strip():
                        latency_ms = (receive_time - last_send_time) * 1000
                        logger.debug(f"ğŸ”„ ElevenLabs partial: '{text[:50]}...' ({latency_ms:.0f}ms)")
                        yield {
                            "text": text,
                            "is_final": False,
                            "latency_ms": latency_ms,
                            "source": "elevenlabs"
                        }

                elif msg_type == "committed_transcript":
                    text = data.get("text", "")
                    if text.strip():
                        latency_ms = (receive_time - last_send_time) * 1000
                        logger.info(f"âœ… ElevenLabs final: '{text}' ({latency_ms:.0f}ms)")
                        yield {
                            "text": text,
                            "is_final": True,
                            "latency_ms": latency_ms,
                            "source": "elevenlabs"
                        }

                elif msg_type == "error":
                    error_msg = data.get("error", "Unknown error")
                    logger.error(f"âŒ ElevenLabs error: {error_msg}")

                # Update last send time for latency calculation
                last_send_time = time.time()

        except websockets.exceptions.ConnectionClosed:
            logger.info("ğŸ”Œ ElevenLabs WebSocket closed")
        except Exception as e:
            logger.error(f"âŒ Error receiving ElevenLabs transcripts: {e}", exc_info=True)
            raise
