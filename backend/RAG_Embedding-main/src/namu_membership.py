#!/usr/bin/env python3
"""
ë‚˜ë¬´ìœ„í‚¤ KT ë©¤ë²„ì‹­ ì •ë³´ í¬ë¡¤ëŸ¬
https://namu.wiki/w/KT%20ë©¤ë²„ì‹­

í…Œì´ë¸”ì€ HTML ì›ë³¸ìœ¼ë¡œ ì €ì¥
"""

import json
import re
import os
from datetime import datetime
from typing import Dict, List, Optional
from bs4 import BeautifulSoup

# Selenium (ë‚˜ë¬´ìœ„í‚¤ ì§ì ‘ ì ‘ê·¼ ì‹œ í•„ìš”)
try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.chrome.service import Service
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False


class NamuKTMembershipCrawler:
    """ë‚˜ë¬´ìœ„í‚¤ KT ë©¤ë²„ì‹­ í¬ë¡¤ëŸ¬"""
    
    # ë‚˜ë¬´ìœ„í‚¤ URL
    TARGET_URL = "https://namu.wiki/w/KT%20%EB%A9%A4%EB%B2%84%EC%8B%AD"
    
    # ë‚˜ë¬´ìœ„í‚¤ CSS ì…€ë ‰í„°
    SELECTORS = {
        'h2': 'h2.PVbZbzR7',      # ëŒ€ë¶„ë¥˜ (2. ë“±ê¸‰, 3. í˜œíƒ ë“±)
        'h3': 'h3.PVbZbzR7',      # ì¤‘ë¶„ë¥˜
        'h4': 'h4.PVbZbzR7',      # ì†Œë¶„ë¥˜
        'h5': 'h5.PVbZbzR7',      # ì„¸ë¶€í•­ëª©
        'h6': 'h6.PVbZbzR7',      # ë” ì„¸ë¶€í•­ëª©
        'table': 'table._3lpnOiRq',
        'table_row': 'tr.R4S-40tq',
        'cell_content': 'div.IBdgNaCn',
    }
    
    def __init__(self):
        self.driver = None
        self.soup = None
        self.results = []
        
    # ========== ë“œë¼ì´ë²„/íŒŒì¼ ë¡œë“œ ==========
    
    def setup_driver(self, headless: bool = False):
        """Selenium ë“œë¼ì´ë²„ ì„¤ì • (ë´‡ íƒì§€ ìš°íšŒ)"""
        if not SELENIUM_AVAILABLE:
            raise ImportError("Seleniumì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: pip install selenium")
        
        options = Options()
        
        # headless ëª¨ë“œ (ì„ íƒì  - ë‚˜ë¬´ìœ„í‚¤ëŠ” headless ì°¨ë‹¨í•  ìˆ˜ ìˆìŒ)
        if headless:
            options.add_argument('--headless=new')
        
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--window-size=1920,1080')
        
        # ë´‡ íƒì§€ ìš°íšŒ ì„¤ì •
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option('excludeSwitches', ['enable-automation'])
        options.add_experimental_option('useAutomationExtension', False)
        
        # ì‹¤ì œ ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ë³´ì´ê²Œ
        options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        self.driver = webdriver.Chrome(options=options)
        
        # navigator.webdriver ì†ì„± ìˆ¨ê¸°ê¸°
        self.driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
            'source': '''
                Object.defineProperty(navigator, 'webdriver', {
                    get: () => undefined
                })
            '''
        })
        
        self.driver.implicitly_wait(10)
        print("âœ… Chrome ë“œë¼ì´ë²„ ì„¤ì • ì™„ë£Œ (ë´‡ íƒì§€ ìš°íšŒ ì ìš©)")
    
    def load_from_url(self, url: str = None, headless: bool = False):
        """URLì—ì„œ í˜ì´ì§€ ë¡œë“œ (Selenium)"""
        if not self.driver:
            self.setup_driver(headless=headless)
        
        target_url = url or self.TARGET_URL
        print(f"ğŸŒ í˜ì´ì§€ ë¡œë“œ ì¤‘: {target_url}")
        
        self.driver.get(target_url)
        
        import time
        time.sleep(3)  # ì´ˆê¸° ë¡œë”© ëŒ€ê¸°
        
        # ì—¬ëŸ¬ ê°€ì§€ ì„ íƒìë¡œ í˜ì´ì§€ ë¡œë“œ í™•ì¸
        selectors_to_try = [
            'article',
            'div.wiki-content',
            'div.content',
            'table',
            'h2'
        ]
        
        page_loaded = False
        for selector in selectors_to_try:
            try:
                WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, selector))
                )
                print(f"  âœ“ '{selector}' ìš”ì†Œ ë°œê²¬")
                page_loaded = True
                break
            except:
                continue
        
        if not page_loaded:
            print("  âš ï¸ íŠ¹ì • ìš”ì†Œë¥¼ ì°¾ì§€ ëª»í–ˆì§€ë§Œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤...")
        
        time.sleep(2)  # ì¶”ê°€ ëŒ€ê¸°
        
        html = self.driver.page_source
        self.soup = BeautifulSoup(html, 'html.parser')
        print(f"âœ… í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ (HTML í¬ê¸°: {len(html):,} bytes)")
        
        # í˜ì´ì§€ ë‚´ìš© ê°„ë‹¨íˆ í™•ì¸
        tables = self.soup.select('table')
        headings = self.soup.select('h2, h3, h4, h5')
        print(f"   ë°œê²¬ëœ í…Œì´ë¸”: {len(tables)}ê°œ, í—¤ë”©: {len(headings)}ê°œ")
    
    def load_from_file(self, filepath: str):
        """ë¡œì»¬ HTML íŒŒì¼ ë¡œë“œ"""
        print(f"ğŸ“‚ íŒŒì¼ ë¡œë“œ ì¤‘: {filepath}")
        
        with open(filepath, 'r', encoding='utf-8') as f:
            html = f.read()
        
        self.soup = BeautifulSoup(html, 'html.parser')
        print(f"âœ… íŒŒì¼ ë¡œë“œ ì™„ë£Œ (HTML í¬ê¸°: {len(html):,} bytes)")
    
    def close(self):
        """ë“œë¼ì´ë²„ ì¢…ë£Œ"""
        if self.driver:
            self.driver.quit()
            print("ğŸ”’ ë“œë¼ì´ë²„ ì¢…ë£Œ")
    
    # ========== í…ìŠ¤íŠ¸ ì¶”ì¶œ ==========
    
    def _extract_heading_text(self, element) -> str:
        """í—¤ë”© í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì•µì»¤ ë“± ì œì™¸)"""
        text = element.get_text(strip=True)
        # ì•ì˜ ë²ˆí˜¸ ì œê±° (ì˜ˆ: "2. ë“±ê¸‰" -> "ë“±ê¸‰")
        text = re.sub(r'^\d+(\.\d+)*\.?\s*', '', text)
        # [í¸ì§‘] ë“± ì œê±°
        text = re.sub(r'\[í¸ì§‘\]', '', text)
        return text.strip()
    
    def _extract_cell_text(self, cell) -> str:
        """ì…€ ë‚´ë¶€ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        content_div = cell.select_one(self.SELECTORS['cell_content'])
        if content_div:
            return content_div.get_text(strip=True)
        return cell.get_text(strip=True)
    
    def _get_following_text(self, element) -> str:
        """ìš”ì†Œ ë’¤ì˜ ì¼ë°˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë‹¤ìŒ êµ¬ì¡° ìš”ì†Œ ì „ê¹Œì§€)"""
        texts = []
        for sibling in element.find_next_siblings():
            # êµ¬ì¡° ìš”ì†Œë¥¼ ë§Œë‚˜ë©´ ì¤‘ë‹¨
            if sibling.name in ['h2', 'h3', 'h4', 'h5', 'h6'] or \
               sibling.select_one('h2, h3, h4, h5, h6'):
                break
            
            # í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
            text = sibling.get_text(strip=True)
            if text:
                texts.append(text)
        
        return ' '.join(texts)[:500] if texts else ''
    
    def _get_section_content(self, start_element, stop_selectors='h2.PVbZbzR7, h3.PVbZbzR7, h4.PVbZbzR7, h5.PVbZbzR7, h6.PVbZbzR7') -> dict:
        """ì„¹ì…˜ì˜ ì „ì²´ ì½˜í…ì¸  ì¶”ì¶œ (í…ìŠ¤íŠ¸ + ë¦¬ìŠ¤íŠ¸ + í…Œì´ë¸”)
        
        ë‚˜ë¬´ìœ„í‚¤ êµ¬ì¡°:
        - í—¤ë”©(h2/h3...) ë‹¤ìŒì— div.Sr34rLtU ë˜ëŠ” div.woJSxwejê°€ ì½˜í…ì¸ ë¥¼ ê°ì‹¸ê³  ìˆìŒ
        - ì‹¤ì œ ì½˜í…ì¸ ëŠ” div.SYMiuyiZ, div.IBdgNaCn, ul.TcQf+vBD ë“±ì— ìˆìŒ
        """
        content = {
            'text': [],           # ì¼ë°˜ í…ìŠ¤íŠ¸
            'list_items': [],     # ë¦¬ìŠ¤íŠ¸ í•­ëª©ë“¤
            'tables': []          # í…Œì´ë¸” (HTML)
        }
        
        # í—¤ë”©ì˜ ë¶€ëª¨ ì»¨í…Œì´ë„ˆë¥¼ ì°¾ì•„ì„œ ë‹¤ìŒ í˜•ì œë“¤ì„ íƒìƒ‰
        # ë‚˜ë¬´ìœ„í‚¤ëŠ” div.woJSxwej ì•ˆì— í—¤ë”©ì´ ìˆê³ , ì½˜í…ì¸ ëŠ” ë‹¤ìŒ í˜•ì œ divì— ìˆìŒ
        parent = start_element.parent
        if parent:
            parent = parent.parent  # í•œ ë‹¨ê³„ ë” ì˜¬ë¼ê°
        
        if not parent:
            parent = start_element
        
        # í˜„ì¬ í—¤ë”© ì´í›„ì˜ ëª¨ë“  ìš”ì†Œë“¤ì„ ìˆœíšŒ
        current = start_element
        
        # find_all_nextë¡œ ì´í›„ ëª¨ë“  ìš”ì†Œ íƒìƒ‰
        for next_elem in start_element.find_all_next():
            # ë‹¤ìŒ í—¤ë”©ì„ ë§Œë‚˜ë©´ ì¤‘ë‹¨
            if next_elem.name in ['h2', 'h3', 'h4', 'h5', 'h6']:
                if 'PVbZbzR7' in next_elem.get('class', []):
                    break
            
            # í…Œì´ë¸” ì²˜ë¦¬ (class="_3lpnOiRq")
            if next_elem.name == 'table' and '_3lpnOiRq' in next_elem.get('class', []):
                table_data = self._parse_table(next_elem)
                content['tables'].append(table_data)
                continue
            
            # ë¦¬ìŠ¤íŠ¸ í•­ëª© ì²˜ë¦¬ (ul.TcQf+vBD ë‚´ë¶€ì˜ li)
            if next_elem.name == 'li':
                # ë¶€ëª¨ê°€ ul.TcQf+vBDì¸ì§€ í™•ì¸
                parent_ul = next_elem.parent
                if parent_ul and parent_ul.name == 'ul':
                    item_text = next_elem.get_text(strip=True)
                    if item_text and item_text not in content['list_items']:
                        content['list_items'].append(item_text)
                continue
            
            # í…ìŠ¤íŠ¸ ì½˜í…ì¸  ì²˜ë¦¬ (div.IBdgNaCn ë‚´ë¶€ í…ìŠ¤íŠ¸)
            if next_elem.name == 'div' and 'IBdgNaCn' in next_elem.get('class', []):
                # ì§ì ‘ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ (ìì‹ íƒœê·¸ì˜ í…ìŠ¤íŠ¸ ì œì™¸í•˜ê³ )
                text = next_elem.get_text(strip=True)
                if text and len(text) > 5:
                    # ì´ë¯¸ ì¶”ê°€ëœ í…ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
                    is_duplicate = False
                    for existing in content['text']:
                        if text in existing or existing in text:
                            is_duplicate = True
                            break
                    if not is_duplicate:
                        content['text'].append(text)
        
        return content
    
    def _get_section_content_html(self, start_element, stop_tags=['h2', 'h3', 'h4', 'h5', 'h6']) -> str:
        """ì„¹ì…˜ì˜ ì „ì²´ HTML ì½˜í…ì¸  ì¶”ì¶œ"""
        html_parts = []
        
        for next_elem in start_element.find_all_next():
            # ë‹¤ìŒ í—¤ë”©ì„ ë§Œë‚˜ë©´ ì¤‘ë‹¨
            if next_elem.name in stop_tags:
                if 'PVbZbzR7' in next_elem.get('class', []):
                    break
            
            # HTML ì¶”ê°€
            html_parts.append(str(next_elem))
        
        return '\n'.join(html_parts)
    
    # ========== í…Œì´ë¸” íŒŒì‹± ==========
    
    def _parse_table(self, table) -> Dict:
        """í…Œì´ë¸” - HTML ì›ë³¸ìœ¼ë¡œ ì €ì¥"""
        
        # í…Œì´ë¸” ì´ë¦„ ì¶”ì¶œ (ì²« ë²ˆì§¸ í–‰ì—ì„œ)
        table_name = ''
        first_row = table.select_one('tr.R4S-40tq')
        if first_row:
            first_cell = first_row.select_one('td')
            if first_cell:
                table_name = self._extract_cell_text(first_cell)
        
        # HTML ì›ë³¸ ì €ì¥ (ì •ë¦¬ëœ ë²„ì „)
        table_html = self._clean_table_html(table)
        
        return {
            'table_name': table_name,
            'table_html': table_html
        }
    
    def _clean_table_html(self, table) -> str:
        """í…Œì´ë¸” HTML ì •ë¦¬"""
        html_str = str(table)
        
        # ë‚˜ë¬´ìœ„í‚¤ íŠ¹ìœ ì˜ data-v ì†ì„± ì œê±°
        html_str = re.sub(r'\s*data-v-[a-z0-9]+=""', '', html_str)
        html_str = re.sub(r'\s*data-dark-style="[^"]*"', '', html_str)
        
        return html_str
    
    # ========== ë©”ì¸ íŒŒì‹± ë¡œì§ ==========
    
    # ì¶”ì¶œí•  h2 ì„¹ì…˜ ë²ˆí˜¸ (3, 4, 5, 6ë²ˆ)
    TARGET_SECTIONS = ['3.', '4.', '5.', '6.']
    
    def _is_target_section(self, heading_text: str) -> bool:
        """ì¶”ì¶œ ëŒ€ìƒ ì„¹ì…˜ì¸ì§€ í™•ì¸ (3., 4., 5., 6.ìœ¼ë¡œ ì‹œì‘)"""
        text = heading_text.strip()
        for prefix in self.TARGET_SECTIONS:
            if text.startswith(prefix):
                return True
        return False
    
    def _get_section_number(self, heading_text: str) -> str:
        """ì„¹ì…˜ ë²ˆí˜¸ ì¶”ì¶œ (ì˜ˆ: '3.1.' -> '3')"""
        text = heading_text.strip()
        match = re.match(r'^(\d+)\.', text)
        if match:
            return match.group(1)
        return ''
    
    def parse_membership_content(self):
        """KT ë©¤ë²„ì‹­ ë‚´ìš© íŒŒì‹± (ê³„ì¸µ êµ¬ì¡°) - 3,4,5,6ë²ˆ ì„¹ì…˜ë§Œ"""
        if not self.soup:
            raise ValueError("ë¨¼ì € load_from_url() ë˜ëŠ” load_from_file()ì„ í˜¸ì¶œí•˜ì„¸ìš”")
        
        print("\nğŸ“Š KT ë©¤ë²„ì‹­ ì •ë³´ íŒŒì‹± ì¤‘...")
        print(f"ğŸ“Œ ì¶”ì¶œ ëŒ€ìƒ ì„¹ì…˜: {self.TARGET_SECTIONS}")
        
        # ë³¸ë¬¸ ì˜ì—­ ì°¾ê¸°
        article = self.soup.select_one('article') or self.soup
        
        # ëª¨ë“  êµ¬ì¡° ìš”ì†Œ ìˆ˜ì§‘ (h2, h3, h4, h5, h6, table)
        all_elements = article.select('h2.PVbZbzR7, h3.PVbZbzR7, h4.PVbZbzR7, h5.PVbZbzR7, h6.PVbZbzR7, table._3lpnOiRq')
        
        print(f"ğŸ“Œ ë°œê²¬ëœ êµ¬ì¡° ìš”ì†Œ: {len(all_elements)}ê°œ")
        
        # ìš”ì†Œë³„ ì¹´ìš´íŠ¸
        counts = {'h2': 0, 'h3': 0, 'h4': 0, 'h5': 0, 'h6': 0, 'table': 0}
        for elem in all_elements:
            if elem.name == 'table':
                counts['table'] += 1
            elif elem.name in counts:
                counts[elem.name] += 1
        print(f"   h2: {counts['h2']}, h3: {counts['h3']}, h4: {counts['h4']}, h5: {counts['h5']}, h6: {counts['h6']}, table: {counts['table']}")
        
        # ê³„ì¸µ êµ¬ì¡°ë¡œ íŒŒì‹± - ëŒ€ìƒ ì„¹ì…˜ë§Œ
        self.results = []
        
        current_h2 = None
        current_h3 = None
        current_h4 = None
        current_h5 = None
        
        # í˜„ì¬ í™œì„± ì„¹ì…˜ ì¶”ì  (3,4,5,6ë²ˆ ì„¹ì…˜ ë‚´ë¶€ì¸ì§€)
        in_target_section = False
        current_main_section = ''  # í˜„ì¬ ë©”ì¸ ì„¹ì…˜ ë²ˆí˜¸ (3, 4, 5, 6)
        
        # í—¤ë”© ìš”ì†Œë§Œ ë¨¼ì € ìˆ˜ì§‘
        heading_elements = [e for e in all_elements if e.name in ['h2', 'h3', 'h4', 'h5', 'h6']]
        
        for i, elem in enumerate(heading_elements):
            # ë‹¤ìŒ í—¤ë”© ì°¾ê¸° (ì½˜í…ì¸  ë²”ìœ„ ê²°ì •ìš©)
            next_heading = heading_elements[i + 1] if i + 1 < len(heading_elements) else None
            
            if elem.name == 'h2':
                # H2ë¥¼ ë§Œë‚˜ë©´ ìƒˆë¡œìš´ ì„¹ì…˜ ì‹œì‘
                heading_text = self._extract_heading_text(elem)
                raw_text = elem.get_text(strip=True)
                
                # ëŒ€ìƒ ì„¹ì…˜ì¸ì§€ í™•ì¸
                if self._is_target_section(raw_text):
                    in_target_section = True
                    current_main_section = self._get_section_number(raw_text)
                    
                    # ì„¹ì…˜ ì½˜í…ì¸  ì¶”ì¶œ
                    content = self._get_section_content(elem)
                    
                    current_h2 = {
                        'section': heading_text,
                        'section_number': raw_text.split()[0] if raw_text else '',
                        'content': content,
                        'sub_sections': []
                    }
                    self.results.append(current_h2)
                    current_h3 = None
                    current_h4 = None
                    current_h5 = None
                    print(f"  âœ… H2: {heading_text} (ì„¹ì…˜ {current_main_section}) - í…ìŠ¤íŠ¸:{len(content['text'])}, ë¦¬ìŠ¤íŠ¸:{len(content['list_items'])}, í…Œì´ë¸”:{len(content['tables'])}")
                else:
                    # ëŒ€ìƒì´ ì•„ë‹Œ ì„¹ì…˜
                    section_num = self._get_section_number(raw_text)
                    if section_num:
                        try:
                            num = int(section_num)
                            if num > 6 or num < 3:
                                in_target_section = False
                                current_main_section = ''
                        except:
                            pass
                    print(f"  â­ï¸ H2: {heading_text} (ê±´ë„ˆëœ€)")
                    current_h2 = None
                    current_h3 = None
                    current_h4 = None
                    current_h5 = None
                
            elif elem.name == 'h3' and in_target_section:
                heading_text = self._extract_heading_text(elem)
                raw_text = elem.get_text(strip=True)
                
                # ì„¹ì…˜ ì½˜í…ì¸  ì¶”ì¶œ
                content = self._get_section_content(elem)
                
                current_h3 = {
                    'name': heading_text,
                    'section_number': raw_text.split()[0] if raw_text else '',
                    'content': content,
                    'sub_sections': []
                }
                if current_h2:
                    current_h2['sub_sections'].append(current_h3)
                current_h4 = None
                current_h5 = None
                print(f"    ğŸ“‚ H3: {heading_text} (í…ìŠ¤íŠ¸:{len(content['text'])}, ë¦¬ìŠ¤íŠ¸:{len(content['list_items'])}, í…Œì´ë¸”:{len(content['tables'])})")
                
            elif elem.name == 'h4' and in_target_section:
                heading_text = self._extract_heading_text(elem)
                
                # ì„¹ì…˜ ì½˜í…ì¸  ì¶”ì¶œ
                content = self._get_section_content(elem)
                
                current_h4 = {
                    'name': heading_text,
                    'content': content,
                    'sub_sections': []
                }
                if current_h3:
                    current_h3['sub_sections'].append(current_h4)
                elif current_h2:
                    current_h2['sub_sections'].append(current_h4)
                current_h5 = None
                print(f"      ğŸ“„ H4: {heading_text} (í…ìŠ¤íŠ¸:{len(content['text'])}, ë¦¬ìŠ¤íŠ¸:{len(content['list_items'])})")
                
            elif elem.name == 'h5' and in_target_section:
                heading_text = self._extract_heading_text(elem)
                
                # ì„¹ì…˜ ì½˜í…ì¸  ì¶”ì¶œ
                content = self._get_section_content(elem)
                
                current_h5 = {
                    'name': heading_text,
                    'content': content,
                    'sub_sections': []
                }
                if current_h4:
                    current_h4['sub_sections'].append(current_h5)
                elif current_h3:
                    current_h3['sub_sections'].append(current_h5)
                print(f"        ğŸ·ï¸ H5: {heading_text}")
                
            elif elem.name == 'h6' and in_target_section:
                heading_text = self._extract_heading_text(elem)
                
                # ì„¹ì…˜ ì½˜í…ì¸  ì¶”ì¶œ
                content = self._get_section_content(elem)
                
                current_h6 = {
                    'name': heading_text,
                    'content': content
                }
                if current_h5:
                    current_h5['sub_sections'].append(current_h6)
                elif current_h4:
                    current_h4['sub_sections'].append(current_h6)
                print(f"          ğŸ“Œ H6: {heading_text}")
        
        print(f"\nâœ… íŒŒì‹± ì™„ë£Œ: {len(self.results)}ê°œ ì„¹ì…˜ (3,4,5,6ë²ˆë§Œ)")
        return self.results
    
    # ========== ì €ì¥ ==========
    
    def save_to_json(self, filename: str = None):
        """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'kt_membership_{timestamp}.json'
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {filename}")
        return filename
    
    def print_summary(self):
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        if not self.results:
            print("âš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print("\n" + "="*60)
        print("ğŸ“Š KT ë©¤ë²„ì‹­ ì •ë³´ ìš”ì•½ (3,4,5,6ë²ˆ ì„¹ì…˜)")
        print("="*60)
        
        def print_content_summary(content, indent=""):
            """ì½˜í…ì¸  ìš”ì•½ ì¶œë ¥"""
            if not content:
                return
            
            # í…ìŠ¤íŠ¸
            if content.get('text'):
                print(f"{indent}ğŸ“ í…ìŠ¤íŠ¸: {len(content['text'])}ê°œ ë‹¨ë½")
                for t in content['text'][:2]:  # ì²˜ìŒ 2ê°œë§Œ
                    preview = t[:50] + '...' if len(t) > 50 else t
                    print(f"{indent}   â€¢ {preview}")
            
            # ë¦¬ìŠ¤íŠ¸
            if content.get('list_items'):
                print(f"{indent}ğŸ“‹ ë¦¬ìŠ¤íŠ¸: {len(content['list_items'])}ê°œ í•­ëª©")
                for item in content['list_items'][:3]:  # ì²˜ìŒ 3ê°œë§Œ
                    preview = item[:60] + '...' if len(item) > 60 else item
                    print(f"{indent}   â€¢ {preview}")
            
            # í…Œì´ë¸”
            if content.get('tables'):
                print(f"{indent}ğŸ“Š í…Œì´ë¸”: {len(content['tables'])}ê°œ")
        
        for section in self.results:
            section_name = section.get('section', '(ì„¹ì…˜)')
            section_num = section.get('section_number', '')
            print(f"\n{'='*50}")
            print(f"ğŸ“ {section_num} {section_name}")
            print(f"{'='*50}")
            
            # H2 ì½˜í…ì¸ 
            if section.get('content'):
                print_content_summary(section['content'], "  ")
            
            # í•˜ìœ„ ì„¹ì…˜ë“¤ (H3)
            for sub in section.get('sub_sections', []):
                sub_name = sub.get('name', '(í•˜ìœ„)')
                sub_num = sub.get('section_number', '')
                print(f"\n  ğŸ“‚ {sub_num} {sub_name}")
                
                if sub.get('content'):
                    print_content_summary(sub['content'], "    ")
                
                # H4 í•˜ìœ„
                for sub2 in sub.get('sub_sections', []):
                    sub2_name = sub2.get('name', '')
                    print(f"\n    ğŸ“„ {sub2_name}")
                    if sub2.get('content'):
                        print_content_summary(sub2['content'], "      ")


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ë‚˜ë¬´ìœ„í‚¤ KT ë©¤ë²„ì‹­ í¬ë¡¤ëŸ¬')
    parser.add_argument('--file', '-f', type=str, help='ë¡œì»¬ HTML íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--url', '-u', type=str, help='í¬ë¡¤ë§í•  URL')
    parser.add_argument('--output', '-o', type=str, help='ì¶œë ¥ JSON íŒŒì¼ëª…')
    parser.add_argument('--headless', action='store_true', help='Headless ëª¨ë“œ (ë¸Œë¼ìš°ì € ì°½ ìˆ¨ê¹€)')
    
    args = parser.parse_args()
    
    crawler = NamuKTMembershipCrawler()
    
    try:
        # ë°ì´í„° ë¡œë“œ
        if args.file:
            crawler.load_from_file(args.file)
        else:
            # ê¸°ë³¸: ë¸Œë¼ìš°ì € ì°½ í‘œì‹œ (ë´‡ íƒì§€ ìš°íšŒì— ìœ ë¦¬)
            crawler.load_from_url(args.url, headless=args.headless)
        
        # íŒŒì‹±
        crawler.parse_membership_content()
        
        # ìš”ì•½ ì¶œë ¥
        crawler.print_summary()
        
        # ì €ì¥
        output_file = crawler.save_to_json(args.output)
        print(f"\nâœ… ì™„ë£Œ! ê²°ê³¼: {output_file}")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    finally:
        crawler.close()


if __name__ == '__main__':
    main()