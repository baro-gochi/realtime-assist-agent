import chromadb
from chromadb.utils import embedding_functions
from openai import OpenAI
from dotenv import load_dotenv
import os

# 1. ì„¤ì •
load_dotenv()
dir =  os.getenv("DIR")
api_key = os.getenv("API_KEY")
CHROMA_DB_PATH = os.getenv("CHROMA_DB_PATH")
COLLECTION_NAME = os.getenv("COLLECTION_NAME")

# OpenAI í´ë¼ì´ì–¸íŠ¸
client = OpenAI(api_key=api_key)

# ChromaDB ì„ë² ë”© í•¨ìˆ˜
openai_ef = embedding_functions.OpenAIEmbeddingFunction(
    api_key=api_key,
    model_name="text-embedding-3-large"
)

# ChromaDB í´ë¼ì´ì–¸íŠ¸ & ì»¬ë ‰ì…˜ ì—°ê²°
chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)

collection = chroma_client.get_collection(
    name=COLLECTION_NAME,
    embedding_function=openai_ef
)


def search_documents(query, n_results=3):
    """ChromaDBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰"""
    results = collection.query(
        query_texts=[query],
        n_results=n_results
    )
    return results


def generate_answer(query, retrieved_docs):
    """ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ GPT-4o-miniê°€ ë‹µë³€ ìƒì„±"""
    
    context = "\n\n".join(retrieved_docs)
    
    prompt = f"""ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•´ì£¼ì„¸ìš”.

[ì°¸ê³  ë¬¸ì„œ]
{context}

[ì§ˆë¬¸]
{query}"""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ë‹µë³€í•©ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        max_tokens=1000,
        temperature=0.3
    )
    
    return response.choices[0].message.content


def rag_query(query, n_results=3):
    """RAG ì „ì²´ íŒŒì´í”„ë¼ì¸: ê²€ìƒ‰ â†’ ë‹µë³€ ìƒì„±"""
    
    print(f"\n{'='*50}")
    print(f"ì§ˆë¬¸: {query}")
    print('='*50)
    
    # 1. ë¬¸ì„œ ê²€ìƒ‰
    results = search_documents(query, n_results)
    retrieved_docs = results['documents'][0]
    
    # 2. ê²€ìƒ‰ëœ ë¬¸ì„œ ì¶œë ¥
    print(f"\nğŸ“„ ê²€ìƒ‰ëœ ë¬¸ì„œ ({len(retrieved_docs)}ê°œ):")
    for i, doc in enumerate(retrieved_docs, 1):
        print(f"\n[{i}] {doc}")
    # 3. ë‹µë³€ ìƒì„±
    answer = generate_answer(query, retrieved_docs)
    
    print(f"\nğŸ’¬ë‹µë³€:")
    print(answer)
    print('='*50)
    
    return answer


if __name__ == "__main__":
    print("ğŸ” RAG í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'q' ë˜ëŠ” 'quit' ì…ë ¥\n")
    
    while True:
        query = input("\nì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        
        if query.lower() in ['q', 'quit', 'ì¢…ë£Œ']:
            print("í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        
        if not query:
            print("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            continue
        
        rag_query(query)