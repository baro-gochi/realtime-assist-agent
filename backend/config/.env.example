# ============================================================
# Logging Configuration
# ============================================================
# 환경: development, staging, production
ENV=development

# 로그 레벨: DEBUG, INFO, WARNING, ERROR, CRITICAL
# - development: DEBUG (상세한 디버깅 정보)
# - staging: DEBUG 또는 INFO (통합 테스트 검증)
# - production: INFO 또는 WARNING (핵심 이벤트만)
LOG_LEVEL=INFO

# 로그 보관 기간 (일) - 기본 60일 (2개월)
# 서버 시작 시 이 기간보다 오래된 로그 파일 자동 삭제
LOG_RETENTION_DAYS=60

# ============================================================
# Google Cloud Speech-to-Text API v2 인증
# Google Cloud Console에서 서비스 계정 키 (JSON) 파일 절대경로
GOOGLE_APPLICATION_CREDENTIALS=path/to/your/service-account-key.json

# Google Cloud 프로젝트 ID (v2 API 필수)
GOOGLE_CLOUD_PROJECT=your-project-id

# Speech-to-Text v2 설정
STT_LANGUAGE_CODE=ko-KR
STT_SAMPLE_RATE_HERTZ=32000
STT_MODEL=short
STT_LOCATION=global
STT_ENABLE_AUTOMATIC_PUNCTUATION=true

# ============================================================
# STT Adaptation (PhraseSet/CustomClass) 설정
# 도메인 특화 용어 인식 정확도 향상
# ============================================================

# Adaptation 기능 활성화 (true/false)
STT_ENABLE_ADAPTATION=true

# Adaptation 설정 파일 경로
# - 미설정 시 기본값: backend/config/stt_phrases.yaml
# - YAML 또는 JSON 형식 지원
# - 설정 파일 예시: backend/config/stt_phrases.yaml.example 참조
STT_ADAPTATION_CONFIG=config/stt_phrases.yaml

# AWS coturn server credentials (Static)
TURN_SERVER_URL=turn:your-server-ip:3478
# TLS
TURN_SERVER_URL=turns:your-server-ip:5349
TURN_USERNAME=your-username
TURN_CREDENTIAL=your-password
STUN_SERVER_URL=stun:your-server-ip:3478

# ============================================================
# LLM / Agent Configuration
# ============================================================

# LLM API Keys
OPENAI_API_KEY=your_openai_api_key

# LLM Model Settings (실시간 분석용)
LLM_MODEL=openai:gpt-4o-mini
LLM_TEMPERATURE=0
LLM_MAX_TOKENS=150
REASONING_EFFORT=minimal

# ============================================================
# Summary LLM Configuration (최종 요약 전용)
# ============================================================
# 세션 종료 시 구조화된 최종 요약 생성용 LLM
# 미설정 시 기본 LLM_MODEL 사용

# 요약 전용 모델 (더 정확한 모델 권장)
SUMMARY_LLM_MODEL=openai:gpt-4o

# 요약 온도 (일관성을 위해 낮은 값 권장)
SUMMARY_LLM_TEMPERATURE=0

# ============================================================
# Redis LLM Caching Configuration
# ============================================================
# Rate Limit 방어 및 지연 시간 단축을 위한 LLM 응답 캐싱

# Redis 연결 URL (기본값: localhost:6379)
REDIS_URL=redis://localhost:6379

# 캐시 활성화 여부 (true/false)
LLM_CACHE_ENABLED=true

# 캐시 타입
# - semantic: 유사 프롬프트 캐싱 (의미적 유사도 기반, 임베딩 사용)
# - exact: 정확히 동일한 프롬프트만 캐싱
# - RedisSearch 모듈이 없는 일반 Redis를 사용할 경우 exact 로 설정
LLM_CACHE_TYPE=semantic

# 캐시 TTL (초) - 기본 1시간 (3600초)
LLM_CACHE_TTL=3600

# 시맨틱 캐시 유사도 임계값 (0~1)
# - 0.1 = 매우 유사한 프롬프트만 캐시 히트 (엄격)
# - 0.2 = 적당히 유사한 프롬프트도 캐시 히트 (관대)
# - 추천: 0.15 (상담 컨텍스트에 적합)
LLM_CACHE_DISTANCE_THRESHOLD=0.15

# 캐시 인덱스 이름 (Redis key prefix)
LLM_CACHE_NAME=kt_agent_llm_cache

# Access Password (Required for production)
# Users must enter this password to access the application
ACCESS_PASSWORD=your_secure_password_here

# RAG Server URL (for external RAG server proxy mode on port 8001)
RAG_SERVER_URL=http://localhost:8001
